#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœºå™¨å­¦ä¹ API
æä¾›æ¨¡å‹è®­ç»ƒã€é¢„æµ‹ã€è¯„ä¼°æ¥å£
"""

from flask import Blueprint, request, jsonify
import traceback
import json
import pandas as pd
from ml_decision_tree import (
    DecisionTreeModel,
    train_and_save_model,
    predict_user_choice
)
from ml_feature_extraction import get_training_data, prepare_features_for_decision_tree, get_db_connection

ml_bp = Blueprint('ml', __name__, url_prefix='/api/ml')


@ml_bp.route('/decision-tree/train', methods=['POST'])
def train_decision_tree():
    """
    è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹
    
    POST /api/ml/decision-tree/train
    {
        "max_depth": 5,
        "min_samples_split": 2,
        "test_size": 0.3
    }
    """
    try:
        data = request.json or {}
        
        print(f"ğŸ“ å¼€å§‹è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹...")
        
        # åŠ è½½æ•°æ®
        df = get_training_data()
        if df is None or len(df) < 5:
            return jsonify({
                'error': 'è®­ç»ƒæ•°æ®ä¸è¶³',
                'message': f'è‡³å°‘éœ€è¦5æ¡å·²å¹³ä»“æ•°æ®ï¼Œå½“å‰: {len(df) if df is not None else 0} æ¡'
            }), 400
        
        # ç‰¹å¾å·¥ç¨‹
        X, y, _ = prepare_features_for_decision_tree(df)
        
        # åˆ›å»ºæ¨¡å‹
        model = DecisionTreeModel(
            max_depth=data.get('max_depth', 5),
            min_samples_split=data.get('min_samples_split', 2),
            min_samples_leaf=data.get('min_samples_leaf', 1)
        )
        
        # è®­ç»ƒ
        performance = model.train(X, y, test_size=data.get('test_size', 0.3))
        
        # ä¿å­˜æ¨¡å‹
        model_path = model.save_model()
        
        # ä¿å­˜æ€§èƒ½åˆ°æ•°æ®åº“
        model.save_performance_to_db(performance)
        
        return jsonify({
            'success': True,
            'model_version': model.model_version,
            'model_path': model_path,
            'performance': {
                'accuracy': performance['accuracy'],
                'f1_score': performance['f1_score'],
                'precision_option': performance['precision_option'],
                'precision_stock': performance['precision_stock'],
                'recall_option': performance['recall_option'],
                'recall_stock': performance['recall_stock'],
                'confusion_matrix': performance['confusion_matrix']
            },
            'training_info': model.training_info,
            'top_features': dict(sorted(
                performance['feature_importance'].items(),
                key=lambda x: x[1],
                reverse=True
            )[:10])
        })
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@ml_bp.route('/decision-tree/predict', methods=['POST'])
def predict_with_decision_tree():
    """
    ä½¿ç”¨å†³ç­–æ ‘é¢„æµ‹ç”¨æˆ·é€‰æ‹©
    
    POST /api/ml/decision-tree/predict
    {
        "features": {
            "volatility": 0.45,
            "rsi": 65.0,
            "current_price": 150.0,
            ...
        }
    }
    """
    try:
        data = request.json
        features = data.get('features')
        
        if not features:
            return jsonify({'error': 'ç¼ºå°‘ç‰¹å¾æ•°æ®'}), 400
        
        # åŠ è½½æ¨¡å‹
        model = DecisionTreeModel.load_model()
        if model is None:
            return jsonify({
                'error': 'æ¨¡å‹æœªæ‰¾åˆ°',
                'message': 'è¯·å…ˆè®­ç»ƒæ¨¡å‹'
            }), 404
        
        # é¢„æµ‹
        result = model.predict(features)
        
        return jsonify({
            'success': True,
            'prediction': result['prediction'],
            'prediction_label': 'æœŸæƒ' if result['prediction'] == 1 else 'è‚¡ç¥¨',
            'confidence': result['confidence'],
            'probabilities': result['probabilities'],
            'model_version': model.model_version
        })
        
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@ml_bp.route('/decision-tree/predict-from-strategy', methods=['POST'])
def predict_from_strategy():
    """
    ä»ç­–ç•¥æ•°æ®ç›´æ¥é¢„æµ‹
    
    POST /api/ml/decision-tree/predict-from-strategy
    {
        "strategy_id": "TSLA_20251115_123456",
        "username": "bbb"
    }
    """
    try:
        data = request.json
        strategy_id = data.get('strategy_id')
        username = data.get('username')
        
        if not strategy_id or not username:
            return jsonify({'error': 'ç¼ºå°‘å¿…è¦å‚æ•°'}), 400
        
        # ä»æ•°æ®åº“è·å–ç­–ç•¥å’Œç”¨æˆ·ä¿¡æ¯
        conn = get_db_connection()
        if not conn:
            return jsonify({'error': 'æ•°æ®åº“è¿æ¥å¤±è´¥'}), 500
        
        try:
            cursor = conn.cursor()
            
            # è·å–ç­–ç•¥ä¿¡æ¯
            cursor.execute("""
                SELECT 
                    s.volatility, s.rsi, s.current_price, s.volume_ratio,
                    s.option_delta, s.option_premium, s.stock_margin, s.notional_value,
                    a.available_cash, a.total_pnl, a.position_count, a.margin_occupied
                FROM strategies s
                JOIN users u ON u.username = %s
                JOIN accounts a ON a.user_id = u.id
                WHERE s.strategy_id = %s
            """, (username, strategy_id))
            
            row = cursor.fetchone()
            if not row:
                cursor.close()
                conn.close()
                return jsonify({'error': 'ç­–ç•¥æˆ–ç”¨æˆ·ä¸å­˜åœ¨'}), 404
            
            # è·å–ç”¨æˆ·ç”»åƒ
            cursor.execute("""
                SELECT 
                    risk_tolerance, investment_style, option_experience,
                    financial_knowledge, decision_speed, confidence_level
                FROM user_profiles
                WHERE username = %s
            """, (username,))
            
            profile_row = cursor.fetchone()
            
            cursor.close()
            conn.close()
            
            # æ„å»ºç‰¹å¾
            features = {
                'volatility': float(row[0]) if row[0] else 0.3,
                'rsi': float(row[1]) if row[1] else 50.0,
                'current_price': float(row[2]) if row[2] else 100.0,
                'volume_ratio': float(row[3]) if row[3] else 1.0,
                'option_delta': float(row[4]) if row[4] else 0.5,
                'option_premium': float(row[5]) if row[5] else 500.0,
                'stock_margin': float(row[6]) if row[6] else 1500.0,
                'notional_value': float(row[7]) if row[7] else 30000.0,
                'available_cash': float(row[8]) if row[8] else 50000.0,
                'total_pnl': float(row[9]) if row[9] else 0.0,
                'position_count': int(row[10]) if row[10] else 0,
                'margin_occupied': float(row[11]) if row[11] else 0.0,
                'confidence_level': 0.5
            }
            
            # ç”¨æˆ·ç”»åƒç¼–ç 
            risk_map = {'conservative': 0, 'moderate': 1, 'aggressive': 2}
            style_map = {'value': 0, 'growth': 1, 'momentum': 2, 'balanced': 3}
            exp_map = {'none': 0, 'basic': 1, 'experienced': 2}
            knowledge_map = {'beginner': 0, 'intermediate': 1, 'advanced': 2}
            speed_map = {'slow': 0, 'moderate': 1, 'fast': 2}
            
            if profile_row:
                features['risk_tolerance_encoded'] = risk_map.get(profile_row[0], 1)
                features['investment_style_encoded'] = style_map.get(profile_row[1], 3)
                features['option_experience_encoded'] = exp_map.get(profile_row[2], 0)
                features['financial_knowledge_encoded'] = knowledge_map.get(profile_row[3], 0)
                features['decision_speed_encoded'] = speed_map.get(profile_row[4], 1)
                features['confidence_level'] = float(profile_row[5]) if profile_row[5] else 0.5
            else:
                # é»˜è®¤å€¼
                features['risk_tolerance_encoded'] = 1
                features['investment_style_encoded'] = 3
                features['option_experience_encoded'] = 0
                features['financial_knowledge_encoded'] = 0
                features['decision_speed_encoded'] = 1
            
            # è¡ç”Ÿç‰¹å¾
            features['cash_to_notional_ratio'] = features['available_cash'] / features['notional_value']
            features['premium_to_margin_ratio'] = features['option_premium'] / (features['stock_margin'] + 1)
            features['pnl_per_position'] = features['total_pnl'] / (features['position_count'] + 1)
            
            # é¢„æµ‹
            model = DecisionTreeModel.load_model()
            if model is None:
                return jsonify({
                    'error': 'æ¨¡å‹æœªæ‰¾åˆ°',
                    'message': 'è¯·å…ˆè®­ç»ƒæ¨¡å‹'
                }), 404
            
            result = model.predict(features)
            
            return jsonify({
                'success': True,
                'strategy_id': strategy_id,
                'username': username,
                'prediction': result['prediction'],
                'prediction_label': 'æœŸæƒ' if result['prediction'] == 1 else 'è‚¡ç¥¨',
                'confidence': result['confidence'],
                'probabilities': result['probabilities'],
                'model_version': model.model_version,
                'features_used': features
            })
            
        except Exception as e:
            if conn:
                conn.close()
            raise e
        
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@ml_bp.route('/decision-tree/status', methods=['GET'])
def get_model_status():
    """
    è·å–æ¨¡å‹çŠ¶æ€
    
    GET /api/ml/decision-tree/status
    """
    try:
        # å°è¯•åŠ è½½æ¨¡å‹
        model = DecisionTreeModel.load_model()
        
        if model is None:
            return jsonify({
                'model_exists': False,
                'message': 'æ¨¡å‹æœªè®­ç»ƒ'
            })
        
        # è·å–æœ€æ–°æ€§èƒ½æŒ‡æ ‡
        conn = get_db_connection()
        performance = None
        
        if conn:
            try:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT 
                        accuracy, f1_score, 
                        precision_option, precision_stock,
                        recall_option, recall_stock,
                        training_samples, test_samples,
                        trained_at
                    FROM ml_model_performance
                    WHERE model_type = 'decision_tree'
                    ORDER BY trained_at DESC
                    LIMIT 1
                """)
                
                row = cursor.fetchone()
                if row:
                    performance = {
                        'accuracy': float(row[0]),
                        'f1_score': float(row[1]),
                        'precision_option': float(row[2]),
                        'precision_stock': float(row[3]),
                        'recall_option': float(row[4]),
                        'recall_stock': float(row[5]),
                        'training_samples': int(row[6]),
                        'test_samples': int(row[7]),
                        'trained_at': row[8].isoformat() if row[8] else None
                    }
                
                cursor.close()
                conn.close()
                
            except Exception as e:
                print(f"âš ï¸ è·å–æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
                if conn:
                    conn.close()
        
        return jsonify({
            'model_exists': True,
            'model_version': model.model_version,
            'feature_count': len(model.feature_names) if model.feature_names else 0,
            'training_info': model.training_info,
            'performance': performance,
            'top_features': dict(sorted(
                model.feature_importance.items(),
                key=lambda x: x[1],
                reverse=True
            )[:10]) if model.feature_importance else {}
        })
        
    except Exception as e:
        print(f"âŒ è·å–æ¨¡å‹çŠ¶æ€å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@ml_bp.route('/training-data/summary', methods=['GET'])
def get_training_data_summary():
    """
    è·å–è®­ç»ƒæ•°æ®æ‘˜è¦
    
    GET /api/ml/training-data/summary
    """
    try:
        from ml_feature_extraction import get_feature_summary
        
        df = get_training_data()
        
        if df is None or len(df) == 0:
            return jsonify({
                'available': False,
                'message': 'æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒæ•°æ®'
            })
        
        summary = get_feature_summary(df)
        
        return jsonify({
            'available': True,
            'summary': summary
        })
        
    except Exception as e:
        print(f"âŒ è·å–è®­ç»ƒæ•°æ®æ‘˜è¦å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@ml_bp.route('/tom-analyze', methods=['POST'])
def tom_analyze_ml():
    """
    è®©Tomåˆ†ææœºå™¨å­¦ä¹ æ¨¡å‹ç»“æœ
    
    POST /api/ml/tom-analyze
    {
        "username": "bbb",
        "model_type": "decision_tree"
    }
    """
    try:
        import os
        from ml_decision_tree import DecisionTreeModel
        from ml_feature_extraction import get_training_data
        
        print("ğŸ” Tomåˆ†æå¼€å§‹...")
        
        data = request.json
        username = data.get('username')
        model_type = data.get('model_type', 'decision_tree')
        
        print(f"ğŸ“ ç”¨æˆ·: {username}, æ¨¡å‹ç±»å‹: {model_type}")
        
        # åŠ è½½æ¨¡å‹
        print("ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹...")
        model = DecisionTreeModel.load_model()
        if not model:
            print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
            return jsonify({'error': 'æ¨¡å‹æœªæ‰¾åˆ°ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹'}), 404
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model.model_version}")
        
        # è·å–å½“å‰ç”¨æˆ·çš„äº¤æ˜“æ•°æ®
        print(f"ğŸ“Š æ­£åœ¨è·å–ç”¨æˆ· {username} çš„äº¤æ˜“æ•°æ®...")
        user_df = get_training_data(username=username)
        
        # å¦‚æœç”¨æˆ·æ•°æ®ä¸è¶³ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        MIN_SAMPLES = 20
        if user_df is None or len(user_df) < MIN_SAMPLES:
            print(f"âš ï¸ ç”¨æˆ· {username} æ•°æ®ä¸è¶³ï¼ˆ{len(user_df) if user_df is not None else 0} æ¡ï¼‰ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...")
            
            # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
            from generate_mock_data import generate_mock_positions_for_user
            try:
                # å…ˆè·å– user_id
                conn = get_db_connection()
                cur = conn.cursor()
                cur.execute("SELECT id FROM users WHERE username = %s", (username,))
                user_result = cur.fetchone()
                
                if not user_result:
                    cur.close()
                    conn.close()
                    return jsonify({'error': f'ç”¨æˆ· {username} ä¸å­˜åœ¨'}), 404
                
                user_id = user_result[0]
                cur.close()
                conn.close()
                
                # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
                num_to_generate = MIN_SAMPLES - (len(user_df) if user_df is not None else 0)
                print(f"   ç”Ÿæˆ {num_to_generate} æ¡æ¨¡æ‹Ÿäº¤æ˜“æ•°æ®...")
                generate_mock_positions_for_user(user_id, num_to_generate)
                
                # é‡æ–°è·å–æ•°æ®
                user_df = get_training_data(username=username)
                print(f"   âœ… æ•°æ®å·²è¡¥å……ï¼Œå½“å‰: {len(user_df)} æ¡")
                
            except Exception as e:
                print(f"   âŒ ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®å¤±è´¥: {e}")
                return jsonify({'error': f'æ— æ³•ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®: {str(e)}'}), 500
        
        if user_df is None or len(user_df) < 5:
            return jsonify({'error': f'ç”¨æˆ· {username} æ•°æ®ä»ç„¶ä¸è¶³ï¼Œæ— æ³•åˆ†æ'}), 400
        
        print(f"âœ… ç”¨æˆ·æ•°æ®å‡†å¤‡å®Œæˆ: {len(user_df)} æ¡äº¤æ˜“è®°å½•")
        
        # ä½¿ç”¨è¯¥ç”¨æˆ·çš„æ•°æ®è®­ç»ƒä¸ªäººæ¨¡å‹
        print(f"ğŸ“ ä¸ºç”¨æˆ· {username} è®­ç»ƒä¸ªäººå†³ç­–æ ‘æ¨¡å‹...")
        from ml_feature_extraction import prepare_features_for_decision_tree
        
        X, y, _ = prepare_features_for_decision_tree(user_df)
        
        # åˆ›å»ºç”¨æˆ·ä¸“å±æ¨¡å‹
        user_model = DecisionTreeModel(max_depth=5, min_samples_split=2, min_samples_leaf=1)
        performance = user_model.train(X, y, test_size=0.2)
        
        print(f"âœ… ç”¨æˆ·æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå‡†ç¡®ç‡: {performance['accuracy']:.2%}")
        
        # ç‰¹å¾é‡è¦æ€§ï¼ˆæ¥è‡ªç”¨æˆ·ä¸ªäººæ¨¡å‹ï¼‰
        top_features = sorted(
            performance['feature_importance'].items(),
            key=lambda x: x[1],
            reverse=True
        )[:5]
        
        # ä»¥ä¸‹ç»Ÿè®¡æ•°æ®éƒ½æ˜¯è¯¥ç”¨æˆ·çš„ä¸ªäººæ•°æ®
        # é€‰æ‹©åˆ†å¸ƒ
        choice_counts = user_df['user_choice'].value_counts()
        option_count = int(choice_counts.get(1, 0))
        stock_count = int(choice_counts.get(2, 0))
        
        # å¹³å‡æ”¶ç›Šï¼ˆå¤„ç†ç©ºæ•°ç»„ï¼‰
        option_df = user_df[user_df['user_choice'] == 1]
        stock_df = user_df[user_df['user_choice'] == 2]
        
        option_return = float(option_df['actual_return'].mean()) if len(option_df) > 0 else 0.0
        stock_return = float(stock_df['actual_return'].mean()) if len(stock_df) > 0 else 0.0
        
        # æœ€ä¼˜é€‰æ‹©ç‡
        optimal_rate = float(user_df['optimal_choice'].mean())
        
        summary = {
            'model_version': f"{username}_personal_{user_model.model_version}",
            'total_samples': len(user_df),
            'accuracy': performance['accuracy'],
            'choice_distribution': {
                'option': option_count,
                'stock': stock_count
            },
            'average_returns': {
                'option': option_return,
                'stock': stock_return
            },
            'optimal_choice_rate': optimal_rate,
            'top_features': [
                {'name': name, 'importance': float(importance), 'rank': i+1}
                for i, (name, importance) in enumerate(top_features)
            ]
        }
        
        # è®©Tomåˆ†æ
        print("ğŸ¤– å‡†å¤‡è°ƒç”¨DeepSeek API...")
        import requests
        deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')
        
        if not deepseek_api_key:
            print("âŒ DEEPSEEK_API_KEY æœªè®¾ç½®")
            return jsonify({'error': 'DEEPSEEK_API_KEY æœªé…ç½®'}), 500
        
        print("âœ… API Key å·²é…ç½®")
        
        # ç¿»è¯‘ç‰¹å¾åç§°ä¸ºä¸­æ–‡
        feature_translations = {
            'cash_to_notional_ratio': 'èµ„é‡‘å……è£•åº¦ï¼ˆè´¦æˆ·å¯ç”¨èµ„é‡‘ä¸äº¤æ˜“é‡‘é¢çš„æ¯”ä¾‹ï¼‰',
            'volume_ratio': 'å¸‚åœºæµåŠ¨æ€§ï¼ˆæˆäº¤é‡ç›¸å¯¹äºå¹³å‡æ°´å¹³çš„æ¯”ä¾‹ï¼‰',
            'volatility': 'å¸‚åœºæ³¢åŠ¨ç‡ï¼ˆä»·æ ¼æ³¢åŠ¨çš„å‰§çƒˆç¨‹åº¦ï¼‰',
            'total_pnl': 'ç´¯è®¡ç›ˆäºï¼ˆä¹‹å‰æ‰€æœ‰äº¤æ˜“çš„æ€»ç›ˆäºï¼‰',
            'available_cash': 'å¯ç”¨èµ„é‡‘ï¼ˆè´¦æˆ·ä¸­å¯ä»¥ç”¨æ¥äº¤æ˜“çš„ç°é‡‘ï¼‰',
            'rsi': 'RSIæŒ‡æ ‡ï¼ˆç›¸å¯¹å¼ºå¼±æŒ‡æ ‡ï¼Œè¡¡é‡è¶…ä¹°è¶…å–ï¼‰',
            'current_price': 'å½“å‰ä»·æ ¼',
            'position_count': 'æŒä»“æ•°é‡',
            'option_delta': 'æœŸæƒDeltaå€¼ï¼ˆæœŸæƒä»·æ ¼å¯¹è‚¡ä»·çš„æ•æ„Ÿåº¦ï¼‰',
            'option_premium': 'æœŸæƒæƒåˆ©é‡‘ï¼ˆè´­ä¹°æœŸæƒéœ€è¦æ”¯ä»˜çš„è´¹ç”¨ï¼‰'
        }
        
        top_features_cn = []
        # å–å‰3ä¸ªç‰¹å¾ï¼Œå¦‚æœä¸è¶³3ä¸ªå°±å–å…¨éƒ¨
        num_features = min(3, len(summary['top_features']))
        for i in range(num_features):
            f = summary['top_features'][i]
            cn_name = feature_translations.get(f['name'], f['name'])
            top_features_cn.append(f"{i+1}. {cn_name}: å½±å“åŠ› {f['importance']*100:.1f}%")
        
        # å¦‚æœæ²¡æœ‰ç‰¹å¾ï¼Œæ·»åŠ é»˜è®¤æç¤º
        if len(top_features_cn) == 0:
            top_features_cn.append("æš‚æ— è¶³å¤Ÿæ•°æ®åˆ†æå…³é”®å› ç´ ")
        
        prompt = f"""ä½ æ˜¯Tomï¼Œä¸€ä½ä¸“ä¸šçš„é‡åŒ–åˆ†æå¸ˆã€‚æˆ‘é€šè¿‡AIç®—æ³•åˆ†æäº†ç”¨æˆ· {username} çš„ {summary['total_samples']} ç¬”äº¤æ˜“è®°å½•ï¼Œå‘ç°äº†ä¸€äº›æœ‰è¶£çš„äº¤æ˜“è¡Œä¸ºæ¨¡å¼ã€‚è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€ï¼Œå¸®åŠ©ç”¨æˆ·äº†è§£è‡ªå·±çš„äº¤æ˜“ä¹ æƒ¯ã€‚

## ç”¨æˆ·çš„äº¤æ˜“æ•°æ®
- äº¤æ˜“æ¬¡æ•°: {summary['total_samples']} ç¬”å·²å¹³ä»“äº¤æ˜“
- æœŸæƒäº¤æ˜“: {summary['choice_distribution']['option']} æ¬¡ï¼ˆ{summary['choice_distribution']['option']/summary['total_samples']*100:.1f}%ï¼‰
- è‚¡ç¥¨äº¤æ˜“: {summary['choice_distribution']['stock']} æ¬¡ï¼ˆ{summary['choice_distribution']['stock']/summary['total_samples']*100:.1f}%ï¼‰
- æœŸæƒå¹³å‡æ”¶ç›Š: {summary['average_returns']['option']:.2%}
- è‚¡ç¥¨å¹³å‡æ”¶ç›Š: {summary['average_returns']['stock']:.2%}

## å½±å“ä½ å†³ç­–çš„å…³é”®å› ç´ ï¼ˆAIå‘ç°ï¼‰
{chr(10).join(top_features_cn)}

è¯·ç”¨**ç¬¬äºŒäººç§°ï¼ˆä½ ï¼‰**ï¼Œä»ä»¥ä¸‹è§’åº¦ç»™å‡ºåˆ†æï¼ˆæ¯ä¸ªè§’åº¦2-3å¥è¯ï¼Œæ€»å…±400å­—ä»¥å†…ï¼‰ï¼š

1. **ä½ çš„äº¤æ˜“é£æ ¼**ï¼šæ ¹æ®æœŸæƒ/è‚¡ç¥¨é€‰æ‹©æ¯”ä¾‹å’Œæ”¶ç›Šæƒ…å†µï¼Œæè¿°ç”¨æˆ·æ˜¯ä»€ä¹ˆç±»å‹çš„äº¤æ˜“è€…

2. **ä½ çš„å†³ç­–ä¾æ®**ï¼š**é‡ç‚¹è§£é‡Š**ä¸Šé¢åˆ—å‡ºçš„Top 3å…³é”®å› ç´ æ˜¯ä»€ä¹ˆæ„æ€ï¼Œä»¥åŠä¸ºä»€ä¹ˆè¿™äº›å› ç´ å¯¹ç”¨æˆ·çš„å†³ç­–å½±å“æœ€å¤§ã€‚ç”¨å¤§ç™½è¯è§£é‡Šï¼Œæ¯”å¦‚"ä½ æœ€çœ‹é‡è´¦æˆ·é‡Œæœ‰å¤šå°‘é’±å¯ä»¥ç”¨"

3. **ä½ çš„ä¼˜åŠ¿**ï¼šæŒ‡å‡ºç”¨æˆ·åšå¾—å¥½çš„åœ°æ–¹ï¼ˆæ¯”å¦‚æ”¶ç›Šç‡ã€é£é™©æ§åˆ¶ç­‰ï¼‰

4. **æ”¹è¿›å»ºè®®**ï¼šç»™å‡º1-2æ¡å…·ä½“çš„ã€å¯æ“ä½œçš„å»ºè®®

æ³¨æ„ï¼š
- ç”¨"ä½ "è€Œä¸æ˜¯"ç”¨æˆ·"
- è¯­æ°”å‹å¥½ã€é¼“åŠ±
- å¿…é¡»ç”¨å¤§ç™½è¯è§£é‡Šé‚£3ä¸ªå…³é”®å› ç´ ï¼Œä¸è¦ç›´æ¥è¯´ä¸“ä¸šæœ¯è¯­
- é‡ç‚¹æ˜¯å¸®åŠ©ç”¨æˆ·äº†è§£è‡ªå·±
"""

        print("ğŸš€ æ­£åœ¨è°ƒç”¨DeepSeek API...")
        headers = {
            "Authorization": f"Bearer {deepseek_api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯Tomï¼Œä¸€ä½ä¸“ä¸šçš„é‡åŒ–åˆ†æå¸ˆå’ŒAIç®—æ³•ä¸“å®¶ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.7,
            "max_tokens": 800
        }
        
        response = requests.post(
            "https://api.deepseek.com/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code != 200:
            print(f"âŒ DeepSeek API é”™è¯¯: {response.status_code}")
            print(f"   å“åº”: {response.text}")
            return jsonify({'error': f'DeepSeek API error: {response.status_code}'}), 500
        
        print("âœ… DeepSeek API è°ƒç”¨æˆåŠŸ")
        analysis = response.json()['choices'][0]['message']['content']
        print(f"ğŸ“ åˆ†æç»“æœé•¿åº¦: {len(analysis)} å­—ç¬¦")
        
        # 1. æ›´æ–°ç”¨æˆ·ç”»åƒ
        print("ğŸ’¾ æ›´æ–°ç”¨æˆ·ç”»åƒ...")
        try:
            conn = get_db_connection()
            cur = conn.cursor()
            
            # æ¨æ–­æŠ•èµ„é£æ ¼
            option_pct = summary['choice_distribution']['option'] / summary['total_samples']
            if option_pct > 0.7:
                risk_tolerance = 'aggressive'
                investment_style = 'momentum'
            elif option_pct > 0.4:
                risk_tolerance = 'moderate'
                investment_style = 'growth'
            else:
                risk_tolerance = 'conservative'
                investment_style = 'value'
            
            # æ›´æ–° user_profilesï¼ˆé€‚é…ç°æœ‰è¡¨ç»“æ„ï¼‰
            cur.execute("""
                INSERT INTO user_profiles (
                    username, 
                    risk_tolerance, 
                    investment_style, 
                    time_horizon,
                    ai_analysis,
                    analysis_summary,
                    last_analyzed_at,
                    updated_at
                )
                VALUES (%s, %s, %s, %s, %s, %s, NOW(), NOW())
                ON CONFLICT (username) 
                DO UPDATE SET
                    risk_tolerance = EXCLUDED.risk_tolerance,
                    investment_style = EXCLUDED.investment_style,
                    time_horizon = EXCLUDED.time_horizon,
                    ai_analysis = EXCLUDED.ai_analysis,
                    analysis_summary = EXCLUDED.analysis_summary,
                    last_analyzed_at = EXCLUDED.last_analyzed_at,
                    updated_at = EXCLUDED.updated_at
            """, (
                username,
                risk_tolerance,  # ç›´æ¥å­˜å‚¨å­—ç¬¦ä¸²
                investment_style,  # ç›´æ¥å­˜å‚¨å­—ç¬¦ä¸²
                'short' if option_pct > 0.6 else 'medium',  # ç›´æ¥å­˜å‚¨å­—ç¬¦ä¸²
                json.dumps({  # JSONBå­—æ®µ
                    'source': 'ml_analysis',
                    'model_version': model.model_version,
                    'analyzed_at': str(pd.Timestamp.now()),
                    'total_samples': summary['total_samples'],
                    'option_preference_pct': float(option_pct * 100),
                    'avg_option_return': float(summary['average_returns']['option']),
                    'avg_stock_return': float(summary['average_returns']['stock']),
                    'key_factors': [f['name'] for f in summary['top_features'][:3]]
                }),
                analysis  # Tomçš„åˆ†æä½œä¸ºæ‘˜è¦
            ))
            
            conn.commit()
            cur.close()
            conn.close()
            print("âœ… ç”¨æˆ·ç”»åƒå·²æ›´æ–°")
        except Exception as e:
            print(f"âš ï¸ æ›´æ–°ç”¨æˆ·ç”»åƒå¤±è´¥: {e}")
        
        # 2. å‘é€åˆ° Tom èŠå¤©è®°å½•
        print("ğŸ’¬ å‘é€åˆ° Tom èŠå¤©...")
        try:
            import datetime
            conn = get_db_connection()
            cur = conn.cursor()
            
            # å…ˆè·å– user_id
            cur.execute("SELECT id FROM users WHERE username = %s", (username,))
            user_result = cur.fetchone()
            
            if not user_result:
                print(f"âš ï¸ ç”¨æˆ· {username} ä¸å­˜åœ¨ï¼Œè·³è¿‡èŠå¤©è®°å½•")
            else:
                user_id = user_result[0]
                
                # è·å–æˆ–åˆ›å»º sessionï¼ˆä½¿ç”¨ session_id å­—æ®µï¼‰
                cur.execute("""
                    SELECT id FROM chat_sessions 
                    WHERE user_id = %s 
                    ORDER BY created_at DESC 
                    LIMIT 1
                """, (user_id,))
                
                result = cur.fetchone()
                if result:
                    session_pk = result[0]
                else:
                    # åˆ›å»ºæ–° session
                    import uuid
                    session_id_str = f"{username}_ml_{uuid.uuid4().hex[:8]}"
                    cur.execute("""
                        INSERT INTO chat_sessions (user_id, session_id, created_at)
                        VALUES (%s, %s, %s)
                        RETURNING id
                    """, (user_id, session_id_str, datetime.datetime.now()))
                    session_pk = cur.fetchone()[0]
                
                # æ’å…¥ç”¨æˆ·æ¶ˆæ¯
                cur.execute("""
                    INSERT INTO chat_messages (session_id, role, content, created_at)
                    VALUES (%s, %s, %s, %s)
                """, (
                    session_pk,
                    'user',
                    f'[ç³»ç»Ÿ] è¯·Tomåˆ†ææˆ‘çš„äº¤æ˜“è¡Œä¸ºï¼ˆåŸºäº{summary["total_samples"]}ç¬”äº¤æ˜“è®°å½•ï¼‰',
                    datetime.datetime.now()
                ))
                
                # æ’å…¥ Tom çš„å›å¤
                cur.execute("""
                    INSERT INTO chat_messages (session_id, role, content, created_at)
                    VALUES (%s, %s, %s, %s)
                """, (
                    session_pk,
                    'assistant',
                    f"ğŸ“Š **äº¤æ˜“è¡Œä¸ºåˆ†ææŠ¥å‘Š**\n\n{analysis}\n\n---\n*åŸºäºAIç®—æ³•åˆ†æ{summary['total_samples']}ç¬”äº¤æ˜“è®°å½•*",
                    datetime.datetime.now()
                ))
                
                conn.commit()
                print("âœ… å·²å‘é€åˆ° Tom èŠå¤©")
            
            cur.close()
            conn.close()
        except Exception as e:
            print(f"âš ï¸ å‘é€èŠå¤©è®°å½•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        return jsonify({
            'success': True,
            'model_version': model.model_version,
            'summary': summary,
            'tom_analysis': analysis
        })
        
    except Exception as e:
        print(f"âŒ Tomåˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


print("âœ… æœºå™¨å­¦ä¹ APIå·²åŠ è½½")

