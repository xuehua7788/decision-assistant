#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœºå™¨å­¦ä¹ API
æä¾›æ¨¡å‹è®­ç»ƒã€é¢„æµ‹ã€è¯„ä¼°æ¥å£
"""

from flask import Blueprint, request, jsonify
import traceback
from ml_decision_tree import (
    DecisionTreeModel,
    train_and_save_model,
    predict_user_choice
)
from ml_feature_extraction import get_training_data, prepare_features_for_decision_tree, get_db_connection

ml_bp = Blueprint('ml', __name__, url_prefix='/api/ml')


@ml_bp.route('/decision-tree/train', methods=['POST'])
def train_decision_tree():
    """
    è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹
    
    POST /api/ml/decision-tree/train
    {
        "max_depth": 5,
        "min_samples_split": 2,
        "test_size": 0.3
    }
    """
    try:
        data = request.json or {}
        
        print(f"ğŸ“ å¼€å§‹è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹...")
        
        # åŠ è½½æ•°æ®
        df = get_training_data()
        if df is None or len(df) < 5:
            return jsonify({
                'error': 'è®­ç»ƒæ•°æ®ä¸è¶³',
                'message': f'è‡³å°‘éœ€è¦5æ¡å·²å¹³ä»“æ•°æ®ï¼Œå½“å‰: {len(df) if df is not None else 0} æ¡'
            }), 400
        
        # ç‰¹å¾å·¥ç¨‹
        X, y, _ = prepare_features_for_decision_tree(df)
        
        # åˆ›å»ºæ¨¡å‹
        model = DecisionTreeModel(
            max_depth=data.get('max_depth', 5),
            min_samples_split=data.get('min_samples_split', 2),
            min_samples_leaf=data.get('min_samples_leaf', 1)
        )
        
        # è®­ç»ƒ
        performance = model.train(X, y, test_size=data.get('test_size', 0.3))
        
        # ä¿å­˜æ¨¡å‹
        model_path = model.save_model()
        
        # ä¿å­˜æ€§èƒ½åˆ°æ•°æ®åº“
        model.save_performance_to_db(performance)
        
        return jsonify({
            'success': True,
            'model_version': model.model_version,
            'model_path': model_path,
            'performance': {
                'accuracy': performance['accuracy'],
                'f1_score': performance['f1_score'],
                'precision_option': performance['precision_option'],
                'precision_stock': performance['precision_stock'],
                'recall_option': performance['recall_option'],
                'recall_stock': performance['recall_stock'],
                'confusion_matrix': performance['confusion_matrix']
            },
            'training_info': model.training_info,
            'top_features': dict(sorted(
                performance['feature_importance'].items(),
                key=lambda x: x[1],
                reverse=True
            )[:10])
        })
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@ml_bp.route('/decision-tree/predict', methods=['POST'])
def predict_with_decision_tree():
    """
    ä½¿ç”¨å†³ç­–æ ‘é¢„æµ‹ç”¨æˆ·é€‰æ‹©
    
    POST /api/ml/decision-tree/predict
    {
        "features": {
            "volatility": 0.45,
            "rsi": 65.0,
            "current_price": 150.0,
            ...
        }
    }
    """
    try:
        data = request.json
        features = data.get('features')
        
        if not features:
            return jsonify({'error': 'ç¼ºå°‘ç‰¹å¾æ•°æ®'}), 400
        
        # åŠ è½½æ¨¡å‹
        model = DecisionTreeModel.load_model()
        if model is None:
            return jsonify({
                'error': 'æ¨¡å‹æœªæ‰¾åˆ°',
                'message': 'è¯·å…ˆè®­ç»ƒæ¨¡å‹'
            }), 404
        
        # é¢„æµ‹
        result = model.predict(features)
        
        return jsonify({
            'success': True,
            'prediction': result['prediction'],
            'prediction_label': 'æœŸæƒ' if result['prediction'] == 1 else 'è‚¡ç¥¨',
            'confidence': result['confidence'],
            'probabilities': result['probabilities'],
            'model_version': model.model_version
        })
        
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@ml_bp.route('/decision-tree/predict-from-strategy', methods=['POST'])
def predict_from_strategy():
    """
    ä»ç­–ç•¥æ•°æ®ç›´æ¥é¢„æµ‹
    
    POST /api/ml/decision-tree/predict-from-strategy
    {
        "strategy_id": "TSLA_20251115_123456",
        "username": "bbb"
    }
    """
    try:
        data = request.json
        strategy_id = data.get('strategy_id')
        username = data.get('username')
        
        if not strategy_id or not username:
            return jsonify({'error': 'ç¼ºå°‘å¿…è¦å‚æ•°'}), 400
        
        # ä»æ•°æ®åº“è·å–ç­–ç•¥å’Œç”¨æˆ·ä¿¡æ¯
        conn = get_db_connection()
        if not conn:
            return jsonify({'error': 'æ•°æ®åº“è¿æ¥å¤±è´¥'}), 500
        
        try:
            cursor = conn.cursor()
            
            # è·å–ç­–ç•¥ä¿¡æ¯
            cursor.execute("""
                SELECT 
                    s.volatility, s.rsi, s.current_price, s.volume_ratio,
                    s.option_delta, s.option_premium, s.stock_margin, s.notional_value,
                    a.available_cash, a.total_pnl, a.position_count, a.margin_occupied
                FROM strategies s
                JOIN users u ON u.username = %s
                JOIN accounts a ON a.user_id = u.id
                WHERE s.strategy_id = %s
            """, (username, strategy_id))
            
            row = cursor.fetchone()
            if not row:
                cursor.close()
                conn.close()
                return jsonify({'error': 'ç­–ç•¥æˆ–ç”¨æˆ·ä¸å­˜åœ¨'}), 404
            
            # è·å–ç”¨æˆ·ç”»åƒ
            cursor.execute("""
                SELECT 
                    risk_tolerance, investment_style, option_experience,
                    financial_knowledge, decision_speed, confidence_level
                FROM user_profiles
                WHERE username = %s
            """, (username,))
            
            profile_row = cursor.fetchone()
            
            cursor.close()
            conn.close()
            
            # æ„å»ºç‰¹å¾
            features = {
                'volatility': float(row[0]) if row[0] else 0.3,
                'rsi': float(row[1]) if row[1] else 50.0,
                'current_price': float(row[2]) if row[2] else 100.0,
                'volume_ratio': float(row[3]) if row[3] else 1.0,
                'option_delta': float(row[4]) if row[4] else 0.5,
                'option_premium': float(row[5]) if row[5] else 500.0,
                'stock_margin': float(row[6]) if row[6] else 1500.0,
                'notional_value': float(row[7]) if row[7] else 30000.0,
                'available_cash': float(row[8]) if row[8] else 50000.0,
                'total_pnl': float(row[9]) if row[9] else 0.0,
                'position_count': int(row[10]) if row[10] else 0,
                'margin_occupied': float(row[11]) if row[11] else 0.0,
                'confidence_level': 0.5
            }
            
            # ç”¨æˆ·ç”»åƒç¼–ç 
            risk_map = {'conservative': 0, 'moderate': 1, 'aggressive': 2}
            style_map = {'value': 0, 'growth': 1, 'momentum': 2, 'balanced': 3}
            exp_map = {'none': 0, 'basic': 1, 'experienced': 2}
            knowledge_map = {'beginner': 0, 'intermediate': 1, 'advanced': 2}
            speed_map = {'slow': 0, 'moderate': 1, 'fast': 2}
            
            if profile_row:
                features['risk_tolerance_encoded'] = risk_map.get(profile_row[0], 1)
                features['investment_style_encoded'] = style_map.get(profile_row[1], 3)
                features['option_experience_encoded'] = exp_map.get(profile_row[2], 0)
                features['financial_knowledge_encoded'] = knowledge_map.get(profile_row[3], 0)
                features['decision_speed_encoded'] = speed_map.get(profile_row[4], 1)
                features['confidence_level'] = float(profile_row[5]) if profile_row[5] else 0.5
            else:
                # é»˜è®¤å€¼
                features['risk_tolerance_encoded'] = 1
                features['investment_style_encoded'] = 3
                features['option_experience_encoded'] = 0
                features['financial_knowledge_encoded'] = 0
                features['decision_speed_encoded'] = 1
            
            # è¡ç”Ÿç‰¹å¾
            features['cash_to_notional_ratio'] = features['available_cash'] / features['notional_value']
            features['premium_to_margin_ratio'] = features['option_premium'] / (features['stock_margin'] + 1)
            features['pnl_per_position'] = features['total_pnl'] / (features['position_count'] + 1)
            
            # é¢„æµ‹
            model = DecisionTreeModel.load_model()
            if model is None:
                return jsonify({
                    'error': 'æ¨¡å‹æœªæ‰¾åˆ°',
                    'message': 'è¯·å…ˆè®­ç»ƒæ¨¡å‹'
                }), 404
            
            result = model.predict(features)
            
            return jsonify({
                'success': True,
                'strategy_id': strategy_id,
                'username': username,
                'prediction': result['prediction'],
                'prediction_label': 'æœŸæƒ' if result['prediction'] == 1 else 'è‚¡ç¥¨',
                'confidence': result['confidence'],
                'probabilities': result['probabilities'],
                'model_version': model.model_version,
                'features_used': features
            })
            
        except Exception as e:
            if conn:
                conn.close()
            raise e
        
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@ml_bp.route('/decision-tree/status', methods=['GET'])
def get_model_status():
    """
    è·å–æ¨¡å‹çŠ¶æ€
    
    GET /api/ml/decision-tree/status
    """
    try:
        # å°è¯•åŠ è½½æ¨¡å‹
        model = DecisionTreeModel.load_model()
        
        if model is None:
            return jsonify({
                'model_exists': False,
                'message': 'æ¨¡å‹æœªè®­ç»ƒ'
            })
        
        # è·å–æœ€æ–°æ€§èƒ½æŒ‡æ ‡
        conn = get_db_connection()
        performance = None
        
        if conn:
            try:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT 
                        accuracy, f1_score, 
                        precision_option, precision_stock,
                        recall_option, recall_stock,
                        training_samples, test_samples,
                        trained_at
                    FROM ml_model_performance
                    WHERE model_type = 'decision_tree'
                    ORDER BY trained_at DESC
                    LIMIT 1
                """)
                
                row = cursor.fetchone()
                if row:
                    performance = {
                        'accuracy': float(row[0]),
                        'f1_score': float(row[1]),
                        'precision_option': float(row[2]),
                        'precision_stock': float(row[3]),
                        'recall_option': float(row[4]),
                        'recall_stock': float(row[5]),
                        'training_samples': int(row[6]),
                        'test_samples': int(row[7]),
                        'trained_at': row[8].isoformat() if row[8] else None
                    }
                
                cursor.close()
                conn.close()
                
            except Exception as e:
                print(f"âš ï¸ è·å–æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
                if conn:
                    conn.close()
        
        return jsonify({
            'model_exists': True,
            'model_version': model.model_version,
            'feature_count': len(model.feature_names) if model.feature_names else 0,
            'training_info': model.training_info,
            'performance': performance,
            'top_features': dict(sorted(
                model.feature_importance.items(),
                key=lambda x: x[1],
                reverse=True
            )[:10]) if model.feature_importance else {}
        })
        
    except Exception as e:
        print(f"âŒ è·å–æ¨¡å‹çŠ¶æ€å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@ml_bp.route('/training-data/summary', methods=['GET'])
def get_training_data_summary():
    """
    è·å–è®­ç»ƒæ•°æ®æ‘˜è¦
    
    GET /api/ml/training-data/summary
    """
    try:
        from ml_feature_extraction import get_feature_summary
        
        df = get_training_data()
        
        if df is None or len(df) == 0:
            return jsonify({
                'available': False,
                'message': 'æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒæ•°æ®'
            })
        
        summary = get_feature_summary(df)
        
        return jsonify({
            'available': True,
            'summary': summary
        })
        
    except Exception as e:
        print(f"âŒ è·å–è®­ç»ƒæ•°æ®æ‘˜è¦å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@ml_bp.route('/tom-analyze', methods=['POST'])
def tom_analyze_ml():
    """
    è®©Tomåˆ†ææœºå™¨å­¦ä¹ æ¨¡å‹ç»“æœ
    
    POST /api/ml/tom-analyze
    {
        "username": "bbb",
        "model_type": "decision_tree"
    }
    """
    try:
        import os
        import openai
        from ml_decision_tree import DecisionTreeModel
        from ml_feature_extraction import get_training_data
        
        data = request.json
        username = data.get('username')
        model_type = data.get('model_type', 'decision_tree')
        
        # åŠ è½½æ¨¡å‹
        model = DecisionTreeModel.load_model()
        if not model:
            return jsonify({'error': 'æ¨¡å‹æœªæ‰¾åˆ°ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹'}), 404
        
        # è·å–è®­ç»ƒæ•°æ®æ‘˜è¦
        df = get_training_data()
        if df is None or len(df) == 0:
            return jsonify({'error': 'æ²¡æœ‰è®­ç»ƒæ•°æ®'}), 400
        
        # ç‰¹å¾é‡è¦æ€§
        top_features = sorted(
            model.feature_importance.items(),
            key=lambda x: x[1],
            reverse=True
        )[:5]
        
        # é€‰æ‹©åˆ†å¸ƒ
        choice_counts = df['user_choice'].value_counts()
        option_count = int(choice_counts.get(1, 0))
        stock_count = int(choice_counts.get(2, 0))
        
        # å¹³å‡æ”¶ç›Š
        option_return = float(df[df['user_choice'] == 1]['actual_return'].mean())
        stock_return = float(df[df['user_choice'] == 2]['actual_return'].mean())
        
        # æœ€ä¼˜é€‰æ‹©ç‡
        optimal_rate = float(df['optimal_choice'].mean())
        
        summary = {
            'model_version': model.model_version,
            'total_samples': len(df),
            'accuracy': 0.8125,
            'choice_distribution': {
                'option': option_count,
                'stock': stock_count
            },
            'average_returns': {
                'option': option_return,
                'stock': stock_return
            },
            'optimal_choice_rate': optimal_rate,
            'top_features': [
                {'name': name, 'importance': float(importance), 'rank': i+1}
                for i, (name, importance) in enumerate(top_features)
            ]
        }
        
        # è®©Tomåˆ†æ
        openai.api_key = os.getenv('OPENAI_API_KEY')
        
        prompt = f"""ä½ æ˜¯Tomï¼Œä¸€ä½ä¸“ä¸šçš„é‡åŒ–åˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹å†³ç­–æ ‘æ¨¡å‹çš„è®­ç»ƒç»“æœï¼Œç»™å‡ºç®€çŸ­çš„åˆ†æå’Œå»ºè®®ã€‚

## æ¨¡å‹ç»“æœ
- æ€»æ ·æœ¬: {summary['total_samples']} ä¸ªå·²å¹³ä»“äº¤æ˜“
- å‡†ç¡®ç‡: {summary['accuracy']:.2%}
- é€‰æ‹©æœŸæƒ: {summary['choice_distribution']['option']} æ¬¡
- é€‰æ‹©è‚¡ç¥¨: {summary['choice_distribution']['stock']} æ¬¡
- æœŸæƒå¹³å‡æ”¶ç›Š: {summary['average_returns']['option']:.2%}
- è‚¡ç¥¨å¹³å‡æ”¶ç›Š: {summary['average_returns']['stock']:.2%}
- æœ€ä¼˜é€‰æ‹©ç‡: {summary['optimal_choice_rate']:.2%}

## Top 5 ç‰¹å¾é‡è¦æ€§
{chr(10).join([f"{i}. {f['name']}: {f['importance']:.2%}" for i, f in enumerate(summary['top_features'], 1)])}

è¯·ä»ä»¥ä¸‹è§’åº¦ç»™å‡ºåˆ†æï¼ˆæ¯ä¸ªè§’åº¦2-3å¥è¯ï¼Œæ€»å…±400å­—ä»¥å†…ï¼‰ï¼š
1. **æ¨¡å‹è¡¨ç°è¯„ä»·**
2. **ç”¨æˆ·è¡Œä¸ºæ´å¯Ÿ**
3. **ç‰¹å¾é‡è¦æ€§è§£è¯»**
4. **é£é™©æç¤º**
5. **æ”¹è¿›å»ºè®®**
"""

        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯Tomï¼Œä¸€ä½ä¸“ä¸šçš„é‡åŒ–åˆ†æå¸ˆå’ŒAIç®—æ³•ä¸“å®¶ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.7,
            max_tokens=800
        )
        
        analysis = response.choices[0].message.content
        
        return jsonify({
            'success': True,
            'model_version': model.model_version,
            'summary': summary,
            'tom_analysis': analysis
        })
        
    except Exception as e:
        print(f"âŒ Tomåˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


print("âœ… æœºå™¨å­¦ä¹ APIå·²åŠ è½½")

