#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœºå™¨å­¦ä¹ ç‰¹å¾æå–æ¨¡å—
ä»ç°æœ‰è¡¨ä¸­æå–è®­ç»ƒæ•°æ®ï¼Œæ— éœ€é¢å¤–å­˜å‚¨
"""

import psycopg2
import pandas as pd
import numpy as np
import os

def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    DATABASE_URL = 'postgresql://decision_user:8P8ZDdFaLp306B0siOZTXGScXmrdS9EB@dpg-d3ot1n3ipnbc739gkn7g-a.singapore-postgres.render.com/decision_assistant_098l'
    try:
        return psycopg2.connect(DATABASE_URL)
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return None

def get_training_data():
    """
    ä»ml_training_dataè§†å›¾è·å–è®­ç»ƒæ•°æ®
    è¿”å›: DataFrame
    """
    conn = get_db_connection()
    if not conn:
        print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
        return None
    
    try:
        query = """
            SELECT * FROM ml_training_data
            WHERE user_choice IS NOT NULL
            ORDER BY decision_time DESC
        """
        
        df = pd.read_sql(query, conn)
        conn.close()
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡è®­ç»ƒæ•°æ®")
        return df
        
    except Exception as e:
        print(f"âŒ åŠ è½½è®­ç»ƒæ•°æ®å¤±è´¥: {e}")
        if conn:
            conn.close()
        return None


def prepare_features_for_bayesian(df):
    """
    ä¸ºæœ´ç´ è´å¶æ–¯å‡†å¤‡ç‰¹å¾ï¼ˆç¦»æ•£åŒ–ï¼‰
    """
    df_discrete = df.copy()
    
    # 1. æ³¢åŠ¨ç‡ç¦»æ•£åŒ–
    df_discrete['volatility_level'] = pd.cut(
        df['volatility'], 
        bins=[0, 0.3, 0.6, 1.0],
        labels=['low', 'medium', 'high']
    )
    
    # 2. RSIç¦»æ•£åŒ–
    df_discrete['rsi_level'] = pd.cut(
        df['rsi'],
        bins=[0, 30, 70, 100],
        labels=['oversold', 'neutral', 'overbought']
    )
    
    # 3. ç°é‡‘æ°´å¹³ç¦»æ•£åŒ–
    cash_median = df['available_cash'].median()
    df_discrete['cash_level'] = pd.cut(
        df['available_cash'],
        bins=[0, cash_median * 0.5, cash_median * 1.5, float('inf')],
        labels=['low', 'medium', 'high']
    )
    
    # 4. ç›ˆäºçŠ¶æ€ç¦»æ•£åŒ–
    df_discrete['pnl_status'] = pd.cut(
        df['total_pnl'],
        bins=[-float('inf'), -100, 100, float('inf')],
        labels=['loss', 'breakeven', 'profit']
    )
    
    # 5. æœŸæƒè´¹æ°´å¹³ç¦»æ•£åŒ–
    premium_median = df['option_premium'].median()
    df_discrete['option_cost_level'] = pd.cut(
        df['option_premium'],
        bins=[0, premium_median * 0.7, premium_median * 1.3, float('inf')],
        labels=['low', 'medium', 'high']
    )
    
    # 6. Deltaå€¼ç¦»æ•£åŒ–
    df_discrete['delta_level'] = pd.cut(
        df['option_delta'],
        bins=[0, 0.3, 0.7, 1.0],
        labels=['low', 'medium', 'high']
    )
    
    # 7. ä¿ç•™åˆ†ç±»ç‰¹å¾ï¼ˆå·²ç»æ˜¯ç¦»æ•£çš„ï¼‰
    categorical_features = [
        'risk_tolerance',
        'investment_style', 
        'option_experience',
        'financial_knowledge',
        'decision_speed'
    ]
    
    # é€‰æ‹©ç‰¹å¾
    feature_columns = [
        'volatility_level', 'rsi_level', 'cash_level', 'pnl_status',
        'option_cost_level', 'delta_level'
    ] + categorical_features
    
    X = df_discrete[feature_columns]
    y = df['user_choice']  # 1=æœŸæƒ, 2=è‚¡ç¥¨
    
    print(f"âœ… è´å¶æ–¯ç‰¹å¾å‡†å¤‡å®Œæˆ: {X.shape[1]} ä¸ªç‰¹å¾")
    return X, y, df_discrete


def prepare_features_for_decision_tree(df):
    """
    ä¸ºå†³ç­–æ ‘å‡†å¤‡ç‰¹å¾ï¼ˆæ•°å€¼+ç¼–ç ï¼‰
    """
    df_encoded = df.copy()
    
    # 1. æ•°å€¼ç‰¹å¾ï¼ˆç›´æ¥ä½¿ç”¨ï¼‰
    numerical_features = [
        'volatility', 'rsi', 'current_price', 'volume_ratio',
        'available_cash', 'total_pnl', 'position_count',
        'option_delta', 'option_premium', 'stock_margin',
        'confidence_level', 'notional_value'
    ]
    
    # 2. åˆ†ç±»ç‰¹å¾ï¼ˆæ ‡ç­¾ç¼–ç ï¼‰
    categorical_mappings = {
        'risk_tolerance': {'conservative': 0, 'moderate': 1, 'aggressive': 2},
        'investment_style': {'value': 0, 'growth': 1, 'momentum': 2, 'balanced': 3},
        'option_experience': {'none': 0, 'basic': 1, 'experienced': 2},
        'financial_knowledge': {'beginner': 0, 'intermediate': 1, 'advanced': 2},
        'decision_speed': {'slow': 0, 'moderate': 1, 'fast': 2}
    }
    
    for col, mapping in categorical_mappings.items():
        if col in df_encoded.columns:
            df_encoded[f'{col}_encoded'] = df_encoded[col].map(mapping)
    
    # 3. è¡ç”Ÿç‰¹å¾
    df_encoded['cash_to_notional_ratio'] = df_encoded['available_cash'] / df_encoded['notional_value']
    df_encoded['premium_to_margin_ratio'] = df_encoded['option_premium'] / (df_encoded['stock_margin'] + 1)
    df_encoded['pnl_per_position'] = df_encoded['total_pnl'] / (df_encoded['position_count'] + 1)
    
    # é€‰æ‹©ç‰¹å¾
    encoded_categorical = [f'{col}_encoded' for col in categorical_mappings.keys() if col in df_encoded.columns]
    derived_features = ['cash_to_notional_ratio', 'premium_to_margin_ratio', 'pnl_per_position']
    
    feature_columns = numerical_features + encoded_categorical + derived_features
    
    # å¤„ç†ç¼ºå¤±å€¼
    X = df_encoded[feature_columns].fillna(df_encoded[feature_columns].median())
    y = df['user_choice']  # 1=æœŸæƒ, 2=è‚¡ç¥¨
    
    print(f"âœ… å†³ç­–æ ‘ç‰¹å¾å‡†å¤‡å®Œæˆ: {X.shape[1]} ä¸ªç‰¹å¾")
    return X, y, df_encoded


def get_feature_summary(df):
    """
    è·å–ç‰¹å¾ç»Ÿè®¡æ‘˜è¦
    """
    summary = {
        'total_samples': len(df),
        'option_choices': (df['user_choice'] == 1).sum(),
        'stock_choices': (df['user_choice'] == 2).sum(),
        'class_balance': {
            'option_ratio': (df['user_choice'] == 1).sum() / len(df),
            'stock_ratio': (df['user_choice'] == 2).sum() / len(df)
        },
        'feature_stats': {
            'volatility': {
                'mean': df['volatility'].mean(),
                'std': df['volatility'].std(),
                'min': df['volatility'].min(),
                'max': df['volatility'].max()
            },
            'rsi': {
                'mean': df['rsi'].mean(),
                'std': df['rsi'].std()
            },
            'available_cash': {
                'mean': df['available_cash'].mean(),
                'median': df['available_cash'].median()
            }
        },
        'user_profiles': {
            'risk_tolerance': df['risk_tolerance'].value_counts().to_dict(),
            'investment_style': df['investment_style'].value_counts().to_dict(),
            'option_experience': df['option_experience'].value_counts().to_dict()
        }
    }
    
    return summary


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ”¬ æœºå™¨å­¦ä¹ ç‰¹å¾æå–æµ‹è¯•")
    print("=" * 60)
    
    # 1. åŠ è½½æ•°æ®
    df = get_training_data()
    if df is None or len(df) == 0:
        print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒæ•°æ®")
        exit(1)
    
    print(f"\nğŸ“Š æ•°æ®æ¦‚è§ˆ:")
    print(df.head())
    
    # 2. ç‰¹å¾æ‘˜è¦
    print(f"\nğŸ“ˆ ç‰¹å¾ç»Ÿè®¡:")
    summary = get_feature_summary(df)
    print(f"   æ€»æ ·æœ¬æ•°: {summary['total_samples']}")
    print(f"   æœŸæƒé€‰æ‹©: {summary['option_choices']} ({summary['class_balance']['option_ratio']:.1%})")
    print(f"   è‚¡ç¥¨é€‰æ‹©: {summary['stock_choices']} ({summary['class_balance']['stock_ratio']:.1%})")
    
    # 3. è´å¶æ–¯ç‰¹å¾
    print(f"\nğŸ² è´å¶æ–¯ç‰¹å¾å‡†å¤‡:")
    X_bayes, y_bayes, df_bayes = prepare_features_for_bayesian(df)
    print(f"   ç‰¹å¾å½¢çŠ¶: {X_bayes.shape}")
    print(f"   ç‰¹å¾åˆ—è¡¨: {list(X_bayes.columns)}")
    
    # 4. å†³ç­–æ ‘ç‰¹å¾
    print(f"\nğŸŒ³ å†³ç­–æ ‘ç‰¹å¾å‡†å¤‡:")
    X_tree, y_tree, df_tree = prepare_features_for_decision_tree(df)
    print(f"   ç‰¹å¾å½¢çŠ¶: {X_tree.shape}")
    print(f"   ç‰¹å¾åˆ—è¡¨: {list(X_tree.columns)}")
    
    print(f"\nâœ… ç‰¹å¾æå–æµ‹è¯•å®Œæˆï¼")

