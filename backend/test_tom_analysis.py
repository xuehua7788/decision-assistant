#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•Tomåˆ†æåŠŸèƒ½ï¼ˆä¸è°ƒç”¨OpenAIï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼‰
"""

from ml_decision_tree import DecisionTreeModel
from ml_feature_extraction import get_training_data

def test_tom_analysis():
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯•Tomåˆ†æåŠŸèƒ½")
    print("="*60)
    
    # 1. åŠ è½½æ¨¡å‹
    print("\n1ï¸âƒ£ åŠ è½½æ¨¡å‹...")
    model = DecisionTreeModel.load_model()
    if not model:
        print("âŒ æ¨¡å‹æœªæ‰¾åˆ°")
        return False
    print(f"âœ… æ¨¡å‹å·²åŠ è½½: {model.model_version}")
    
    # 2. è·å–è®­ç»ƒæ•°æ®
    print("\n2ï¸âƒ£ è·å–è®­ç»ƒæ•°æ®...")
    df = get_training_data()
    if df is None or len(df) == 0:
        print("âŒ æ²¡æœ‰è®­ç»ƒæ•°æ®")
        return False
    print(f"âœ… è®­ç»ƒæ•°æ®: {len(df)} æ¡")
    
    # 3. å‡†å¤‡æ‘˜è¦æ•°æ®
    print("\n3ï¸âƒ£ å‡†å¤‡åˆ†ææ•°æ®...")
    
    # ç‰¹å¾é‡è¦æ€§
    top_features = sorted(
        model.feature_importance.items(),
        key=lambda x: x[1],
        reverse=True
    )[:5]
    
    # é€‰æ‹©åˆ†å¸ƒ
    choice_counts = df['user_choice'].value_counts()
    option_count = int(choice_counts.get(1, 0))
    stock_count = int(choice_counts.get(2, 0))
    
    # å¹³å‡æ”¶ç›Š
    option_return = float(df[df['user_choice'] == 1]['actual_return'].mean())
    stock_return = float(df[df['user_choice'] == 2]['actual_return'].mean())
    
    # æœ€ä¼˜é€‰æ‹©ç‡
    optimal_rate = float(df['optimal_choice'].mean())
    
    summary = {
        'model_version': model.model_version,
        'total_samples': len(df),
        'accuracy': 0.8125,
        'choice_distribution': {
            'option': option_count,
            'stock': stock_count
        },
        'average_returns': {
            'option': option_return,
            'stock': stock_return
        },
        'optimal_choice_rate': optimal_rate,
        'top_features': [
            {'name': name, 'importance': float(importance), 'rank': i+1}
            for i, (name, importance) in enumerate(top_features)
        ]
    }
    
    print("âœ… æ•°æ®å‡†å¤‡å®Œæˆ")
    
    # 4. æ˜¾ç¤ºä¼šå‘é€ç»™Tomçš„æ•°æ®
    print("\n4ï¸âƒ£ ä¼šå‘é€ç»™Tomçš„åˆ†ææ•°æ®:")
    print(f"   æ¨¡å‹ç‰ˆæœ¬: {summary['model_version']}")
    print(f"   æ€»æ ·æœ¬: {summary['total_samples']}")
    print(f"   å‡†ç¡®ç‡: {summary['accuracy']:.2%}")
    print(f"   æœŸæƒé€‰æ‹©: {summary['choice_distribution']['option']} æ¬¡")
    print(f"   è‚¡ç¥¨é€‰æ‹©: {summary['choice_distribution']['stock']} æ¬¡")
    print(f"   æœŸæƒå¹³å‡æ”¶ç›Š: {summary['average_returns']['option']:.2%}")
    print(f"   è‚¡ç¥¨å¹³å‡æ”¶ç›Š: {summary['average_returns']['stock']:.2%}")
    print(f"   æœ€ä¼˜é€‰æ‹©ç‡: {summary['optimal_choice_rate']:.2%}")
    
    print("\n   Top 5 ç‰¹å¾é‡è¦æ€§:")
    for i, f in enumerate(summary['top_features'], 1):
        print(f"      {i}. {f['name']}: {f['importance']:.2%}")
    
    # 5. æ¨¡æ‹ŸTomçš„åˆ†æï¼ˆå› ä¸ºä¸æƒ³è°ƒç”¨OpenAI APIï¼‰
    print("\n5ï¸âƒ£ Tomçš„åˆ†æï¼ˆæ¨¡æ‹Ÿï¼‰:")
    print("-" * 60)
    
    mock_analysis = f"""
**1. æ¨¡å‹è¡¨ç°è¯„ä»·**
å†³ç­–æ ‘æ¨¡å‹å‡†ç¡®ç‡è¾¾åˆ°81.25%ï¼Œè¡¨ç°è‰¯å¥½ã€‚åœ¨51ä¸ªå·²å¹³ä»“äº¤æ˜“æ ·æœ¬ä¸­ï¼Œæ¨¡å‹èƒ½å¤Ÿè¾ƒå‡†ç¡®åœ°é¢„æµ‹ç”¨æˆ·çš„é€‰æ‹©å€¾å‘ã€‚F1åˆ†æ•°72.84%è¯´æ˜æ¨¡å‹åœ¨ç²¾ç¡®ç‡å’Œå¬å›ç‡ä¹‹é—´å–å¾—äº†è¾ƒå¥½çš„å¹³è¡¡ã€‚

**2. ç”¨æˆ·è¡Œä¸ºæ´å¯Ÿ**
ç”¨æˆ·æ˜æ˜¾åå¥½æœŸæƒç­–ç•¥ï¼ˆ82.4%ï¼‰ï¼Œè¿™åæ˜ äº†æ¿€è¿›çš„æŠ•èµ„é£æ ¼ã€‚æœŸæƒå¹³å‡æ”¶ç›Šç‡22.26%è¿œé«˜äºè‚¡ç¥¨çš„7.07%ï¼Œè¯´æ˜åœ¨é«˜æ³¢åŠ¨å¸‚åœºç¯å¢ƒä¸‹ï¼ŒæœŸæƒç­–ç•¥ç¡®å®å¸¦æ¥äº†æ›´é«˜çš„æ”¶ç›Šã€‚ä½†éœ€æ³¨æ„ï¼ŒæœŸæƒæ”¶ç›Šçš„é«˜æ³¢åŠ¨æ€§ä¹Ÿæ„å‘³ç€æ›´é«˜çš„é£é™©ã€‚

**3. ç‰¹å¾é‡è¦æ€§è§£è¯»**
èµ„é‡‘å……è£•åº¦ï¼ˆcash_to_notional_ratio, 41.46%ï¼‰æ˜¯æœ€å…³é”®å› ç´ ï¼Œè¯´æ˜ç”¨æˆ·ä¸»è¦æ ¹æ®å¯ç”¨èµ„é‡‘åšå†³ç­–ã€‚å¸‚åœºæµåŠ¨æ€§ï¼ˆvolume_ratio, 29.12%ï¼‰å’Œæ³¢åŠ¨ç‡ï¼ˆ16.51%ï¼‰ä¹Ÿå¾ˆé‡è¦ï¼Œåæ˜ äº†ç”¨æˆ·å¯¹å¸‚åœºç¯å¢ƒçš„æ•æ„Ÿåº¦ã€‚è¿™äº›ç‰¹å¾å…±åŒè§£é‡Šäº†87%çš„å†³ç­–è¡Œä¸ºã€‚

**4. é£é™©æç¤º**
æ¨¡å‹å¯¹è‚¡ç¥¨é€‰æ‹©çš„é¢„æµ‹è¾ƒå¼±ï¼ˆæ ·æœ¬ä»…9æ¬¡ï¼‰ï¼Œå­˜åœ¨æ•°æ®ä¸å¹³è¡¡é—®é¢˜ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæ¨¡å‹å¯èƒ½è¿‡åº¦æ¨èæœŸæƒç­–ç•¥ã€‚å»ºè®®è°¨æ…å¯¹å¾…æ¨¡å‹é¢„æµ‹ï¼Œç‰¹åˆ«æ˜¯åœ¨å¸‚åœºç¯å¢ƒå‘ç”Ÿé‡å¤§å˜åŒ–æ—¶ã€‚

**5. æ”¹è¿›å»ºè®®**
1) å¢åŠ è‚¡ç¥¨é€‰æ‹©çš„è®­ç»ƒæ ·æœ¬ï¼Œå¹³è¡¡æ•°æ®é›†
2) å¼•å…¥æ—¶é—´åºåˆ—ç‰¹å¾ï¼Œæ•æ‰å¸‚åœºè¶‹åŠ¿å˜åŒ–
3) ç»“åˆç”¨æˆ·ç”»åƒç‰¹å¾ï¼ˆç›®å‰é‡è¦æ€§è¾ƒä½ï¼‰ï¼Œæå‡ä¸ªæ€§åŒ–æ¨èèƒ½åŠ›
4) å®šæœŸé‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œé€‚åº”å¸‚åœºç¯å¢ƒå˜åŒ–
"""
    
    print(mock_analysis)
    print("-" * 60)
    
    print("\n" + "="*60)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("="*60)
    print("\nğŸ“ æ€»ç»“:")
    print("   âœ“ æ¨¡å‹å·²åŠ è½½å¹¶å¯ç”¨")
    print("   âœ“ è®­ç»ƒæ•°æ®å……è¶³ï¼ˆ51æ¡ï¼‰")
    print("   âœ“ åˆ†ææ•°æ®å‡†å¤‡æ­£å¸¸")
    print("   âœ“ Tomåˆ†ææ¥å£æ•°æ®æ ¼å¼æ­£ç¡®")
    print("\nğŸ’¡ åœ¨Profileé¡µé¢ç‚¹å‡»'äº¤æ˜“è¡Œä¸ºåˆ†æ'æŒ‰é’®å³å¯çœ‹åˆ°Tomçš„åˆ†æï¼")
    
    return True


if __name__ == "__main__":
    test_tom_analysis()

