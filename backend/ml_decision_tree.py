#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†³ç­–æ ‘ç®—æ³•å®ç°
ç”¨äºé¢„æµ‹ç”¨æˆ·äº¤æ˜“è¡Œä¸ºï¼ˆé€‰æ‹©æœŸæƒè¿˜æ˜¯è‚¡ç¥¨ï¼‰
"""

import numpy as np
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report
)
import joblib
import json
from datetime import datetime
import os

from ml_feature_extraction import (
    get_training_data,
    prepare_features_for_decision_tree,
    get_feature_summary,
    get_db_connection
)


class DecisionTreeModel:
    """å†³ç­–æ ‘æ¨¡å‹ç±»"""
    
    def __init__(self, max_depth=5, min_samples_split=2, min_samples_leaf=1):
        """
        åˆå§‹åŒ–å†³ç­–æ ‘æ¨¡å‹
        
        å‚æ•°:
            max_depth: æœ€å¤§æ·±åº¦ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
            min_samples_split: åˆ†è£‚æ‰€éœ€æœ€å°æ ·æœ¬æ•°
            min_samples_leaf: å¶èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°
        """
        self.model = DecisionTreeClassifier(
            max_depth=max_depth,
            min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf,
            random_state=42,
            class_weight='balanced'  # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
        )
        self.feature_names = None
        self.feature_importance = None
        self.model_version = f"v1.0_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.training_info = {}
        
    
    def train(self, X, y, test_size=0.3):
        """
        è®­ç»ƒæ¨¡å‹
        
        å‚æ•°:
            X: ç‰¹å¾çŸ©é˜µ
            y: æ ‡ç­¾å‘é‡
            test_size: æµ‹è¯•é›†æ¯”ä¾‹
            
        è¿”å›:
            performance: æ€§èƒ½æŒ‡æ ‡å­—å…¸
        """
        print(f"\n{'='*60}")
        print(f"ğŸŒ³ å¼€å§‹è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹")
        print(f"{'='*60}")
        
        # 1. æ•°æ®åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )
        
        print(f"ğŸ“Š æ•°æ®åˆ†å‰²:")
        print(f"   è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
        print(f"   æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
        print(f"   ç‰¹å¾æ•°: {X_train.shape[1]}")
        
        # 2. è®­ç»ƒæ¨¡å‹
        print(f"\nğŸ”„ è®­ç»ƒä¸­...")
        self.model.fit(X_train, y_train)
        self.feature_names = list(X.columns)
        self.feature_importance = dict(zip(
            self.feature_names,
            self.model.feature_importances_
        ))
        
        print(f"âœ… è®­ç»ƒå®Œæˆï¼")
        
        # 3. é¢„æµ‹
        y_train_pred = self.model.predict(X_train)
        y_test_pred = self.model.predict(X_test)
        
        # 4. è¯„ä¼°
        performance = self._evaluate(
            y_train, y_train_pred,
            y_test, y_test_pred,
            X_train, X_test
        )
        
        # 5. ä¿å­˜è®­ç»ƒä¿¡æ¯
        self.training_info = {
            'train_samples': len(X_train),
            'test_samples': len(X_test),
            'train_test_split': test_size,
            'hyperparameters': {
                'max_depth': self.model.max_depth,
                'min_samples_split': self.model.min_samples_split,
                'min_samples_leaf': self.model.min_samples_leaf
            },
            'trained_at': datetime.now().isoformat()
        }
        
        return performance
    
    
    def _evaluate(self, y_train, y_train_pred, y_test, y_test_pred, X_train, X_test):
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        """
        print(f"\n{'='*60}")
        print(f"ğŸ“ˆ æ¨¡å‹æ€§èƒ½è¯„ä¼°")
        print(f"{'='*60}")
        
        # è®­ç»ƒé›†æ€§èƒ½
        train_accuracy = accuracy_score(y_train, y_train_pred)
        print(f"\nğŸ¯ è®­ç»ƒé›†:")
        print(f"   å‡†ç¡®ç‡: {train_accuracy:.2%}")
        
        # æµ‹è¯•é›†æ€§èƒ½
        test_accuracy = accuracy_score(y_test, y_test_pred)
        test_precision_option = precision_score(y_test, y_test_pred, pos_label=1, zero_division=0)
        test_precision_stock = precision_score(y_test, y_test_pred, pos_label=2, zero_division=0)
        test_recall_option = recall_score(y_test, y_test_pred, pos_label=1, zero_division=0)
        test_recall_stock = recall_score(y_test, y_test_pred, pos_label=2, zero_division=0)
        test_f1 = f1_score(y_test, y_test_pred, average='weighted')
        
        print(f"\nğŸ¯ æµ‹è¯•é›†:")
        print(f"   å‡†ç¡®ç‡: {test_accuracy:.2%}")
        print(f"   F1åˆ†æ•°: {test_f1:.2%}")
        print(f"\n   æœŸæƒç­–ç•¥ (1):")
        print(f"      ç²¾ç¡®ç‡: {test_precision_option:.2%}")
        print(f"      å¬å›ç‡: {test_recall_option:.2%}")
        print(f"\n   è‚¡ç¥¨ç­–ç•¥ (2):")
        print(f"      ç²¾ç¡®ç‡: {test_precision_stock:.2%}")
        print(f"      å¬å›ç‡: {test_recall_stock:.2%}")
        
        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(y_test, y_test_pred)
        print(f"\nğŸ“Š æ··æ·†çŸ©é˜µ:")
        print(f"                é¢„æµ‹æœŸæƒ  é¢„æµ‹è‚¡ç¥¨")
        print(f"   å®é™…æœŸæƒ:      {cm[0][0]:>4}      {cm[0][1]:>4}")
        print(f"   å®é™…è‚¡ç¥¨:      {cm[1][0]:>4}      {cm[1][1]:>4}")
        
        # ç‰¹å¾é‡è¦æ€§
        print(f"\nğŸ” Top 10 ç‰¹å¾é‡è¦æ€§:")
        sorted_features = sorted(
            self.feature_importance.items(),
            key=lambda x: x[1],
            reverse=True
        )
        for i, (feature, importance) in enumerate(sorted_features[:10], 1):
            print(f"   {i:2d}. {feature:30s} {importance:.4f}")
        
        # äº¤å‰éªŒè¯
        cv_scores = cross_val_score(
            self.model, X_train, y_train, cv=min(5, len(X_train)), scoring='accuracy'
        )
        print(f"\nğŸ”„ 5æŠ˜äº¤å‰éªŒè¯:")
        print(f"   å¹³å‡å‡†ç¡®ç‡: {cv_scores.mean():.2%} (+/- {cv_scores.std() * 2:.2%})")
        
        # è¿”å›æ€§èƒ½æŒ‡æ ‡
        performance = {
            'accuracy': float(test_accuracy),
            'precision_option': float(test_precision_option),
            'precision_stock': float(test_precision_stock),
            'recall_option': float(test_recall_option),
            'recall_stock': float(test_recall_stock),
            'f1_score': float(test_f1),
            'confusion_matrix': {
                'TN': int(cm[0][0]),  # é¢„æµ‹æœŸæƒï¼Œå®é™…æœŸæƒ
                'FP': int(cm[0][1]),  # é¢„æµ‹è‚¡ç¥¨ï¼Œå®é™…æœŸæƒ
                'FN': int(cm[1][0]),  # é¢„æµ‹æœŸæƒï¼Œå®é™…è‚¡ç¥¨
                'TP': int(cm[1][1])   # é¢„æµ‹è‚¡ç¥¨ï¼Œå®é™…è‚¡ç¥¨
            },
            'feature_importance': self.feature_importance,
            'cv_mean': float(cv_scores.mean()),
            'cv_std': float(cv_scores.std()),
            'train_accuracy': float(train_accuracy)
        }
        
        return performance
    
    
    def predict(self, X):
        """
        é¢„æµ‹å•ä¸ªæ ·æœ¬
        
        å‚æ•°:
            X: ç‰¹å¾å‘é‡æˆ–DataFrame
            
        è¿”å›:
            prediction: é¢„æµ‹ç»“æœ (1=æœŸæƒ, 2=è‚¡ç¥¨)
            confidence: é¢„æµ‹ç½®ä¿¡åº¦
            probabilities: å„ç±»åˆ«æ¦‚ç‡
        """
        if isinstance(X, pd.Series):
            X = X.to_frame().T
        elif isinstance(X, dict):
            X = pd.DataFrame([X])
        
        # ç¡®ä¿ç‰¹å¾é¡ºåºä¸€è‡´
        if self.feature_names:
            X = X[self.feature_names]
        
        # é¢„æµ‹
        prediction = self.model.predict(X)[0]
        probabilities = self.model.predict_proba(X)[0]
        confidence = max(probabilities)
        
        return {
            'prediction': int(prediction),
            'confidence': float(confidence),
            'probabilities': {
                'option': float(probabilities[0]),
                'stock': float(probabilities[1])
            }
        }
    
    
    def save_model(self, filepath='models/decision_tree_model.pkl'):
        """ä¿å­˜æ¨¡å‹åˆ°æ–‡ä»¶"""
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        model_data = {
            'model': self.model,
            'feature_names': self.feature_names,
            'feature_importance': self.feature_importance,
            'model_version': self.model_version,
            'training_info': self.training_info
        }
        
        joblib.dump(model_data, filepath)
        print(f"\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {filepath}")
        return filepath
    
    
    @classmethod
    def load_model(cls, filepath='models/decision_tree_model.pkl'):
        """ä»æ–‡ä»¶åŠ è½½æ¨¡å‹"""
        if not os.path.exists(filepath):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            return None
        
        model_data = joblib.load(filepath)
        
        instance = cls()
        instance.model = model_data['model']
        instance.feature_names = model_data['feature_names']
        instance.feature_importance = model_data['feature_importance']
        instance.model_version = model_data['model_version']
        instance.training_info = model_data.get('training_info', {})
        
        print(f"âœ… æ¨¡å‹å·²åŠ è½½: {filepath}")
        print(f"   ç‰ˆæœ¬: {instance.model_version}")
        return instance
    
    
    def save_performance_to_db(self, performance):
        """ä¿å­˜æ€§èƒ½æŒ‡æ ‡åˆ°æ•°æ®åº“"""
        conn = get_db_connection()
        if not conn:
            print("âš ï¸ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œæ— æ³•ä¿å­˜æ€§èƒ½æŒ‡æ ‡")
            return False
        
        try:
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO ml_model_performance (
                    model_type, model_version,
                    accuracy, precision_option, precision_stock,
                    recall_option, recall_stock, f1_score,
                    confusion_matrix, feature_importance,
                    training_samples, test_samples, train_test_split,
                    hyperparameters
                ) VALUES (
                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
                )
            """, (
                'decision_tree',
                self.model_version,
                performance['accuracy'],
                performance['precision_option'],
                performance['precision_stock'],
                performance['recall_option'],
                performance['recall_stock'],
                performance['f1_score'],
                json.dumps(performance['confusion_matrix']),
                json.dumps(performance['feature_importance']),
                self.training_info['train_samples'],
                self.training_info['test_samples'],
                self.training_info['train_test_split'],
                json.dumps(self.training_info['hyperparameters'])
            ))
            
            conn.commit()
            cursor.close()
            conn.close()
            
            print(f"âœ… æ€§èƒ½æŒ‡æ ‡å·²ä¿å­˜åˆ°æ•°æ®åº“")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
            if conn:
                conn.close()
            return False


def train_and_save_model():
    """è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹çš„å®Œæ•´æµç¨‹"""
    print(f"\n{'='*60}")
    print(f"ğŸš€ å†³ç­–æ ‘æ¨¡å‹è®­ç»ƒæµç¨‹")
    print(f"{'='*60}")
    
    # 1. åŠ è½½æ•°æ®
    print(f"\nğŸ“¥ Step 1: åŠ è½½è®­ç»ƒæ•°æ®...")
    df = get_training_data()
    
    if df is None or len(df) < 5:
        print(f"âŒ è®­ç»ƒæ•°æ®ä¸è¶³ï¼ˆè‡³å°‘éœ€è¦5æ¡ï¼‰ï¼Œå½“å‰: {len(df) if df is not None else 0} æ¡")
        return None
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡æ•°æ®")
    
    # 2. ç‰¹å¾å·¥ç¨‹
    print(f"\nğŸ”§ Step 2: ç‰¹å¾å·¥ç¨‹...")
    X, y, df_processed = prepare_features_for_decision_tree(df)
    
    # 3. è®­ç»ƒæ¨¡å‹
    print(f"\nğŸ“ Step 3: è®­ç»ƒæ¨¡å‹...")
    model = DecisionTreeModel(
        max_depth=5,
        min_samples_split=2,
        min_samples_leaf=1
    )
    
    performance = model.train(X, y, test_size=0.3)
    
    # 4. ä¿å­˜æ¨¡å‹
    print(f"\nğŸ’¾ Step 4: ä¿å­˜æ¨¡å‹...")
    model_path = model.save_model()
    
    # 5. ä¿å­˜æ€§èƒ½åˆ°æ•°æ®åº“
    print(f"\nğŸ“Š Step 5: ä¿å­˜æ€§èƒ½æŒ‡æ ‡...")
    model.save_performance_to_db(performance)
    
    print(f"\n{'='*60}")
    print(f"âœ… è®­ç»ƒæµç¨‹å®Œæˆï¼")
    print(f"{'='*60}")
    print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: {model_path}")
    print(f"ğŸ“ˆ æµ‹è¯•å‡†ç¡®ç‡: {performance['accuracy']:.2%}")
    print(f"ğŸ¯ F1åˆ†æ•°: {performance['f1_score']:.2%}")
    
    return model


def predict_user_choice(features):
    """
    é¢„æµ‹ç”¨æˆ·é€‰æ‹©
    
    å‚æ•°:
        features: ç‰¹å¾å­—å…¸
        
    è¿”å›:
        prediction_result: é¢„æµ‹ç»“æœå­—å…¸
    """
    # åŠ è½½æ¨¡å‹
    model = DecisionTreeModel.load_model()
    if model is None:
        return {'error': 'æ¨¡å‹æœªæ‰¾åˆ°ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹'}
    
    # é¢„æµ‹
    result = model.predict(features)
    
    return result


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == 'train':
        # è®­ç»ƒæ¨¡å¼
        train_and_save_model()
        
    elif len(sys.argv) > 1 and sys.argv[1] == 'test':
        # æµ‹è¯•æ¨¡å¼
        print(f"\n{'='*60}")
        print(f"ğŸ§ª æµ‹è¯•é¢„æµ‹åŠŸèƒ½")
        print(f"{'='*60}")
        
        # åŠ è½½æ¨¡å‹
        model = DecisionTreeModel.load_model()
        if model is None:
            print("âŒ è¯·å…ˆè®­ç»ƒæ¨¡å‹: python ml_decision_tree.py train")
            sys.exit(1)
        
        # æµ‹è¯•æ ·æœ¬
        test_features = {
            'volatility': 0.45,
            'rsi': 65.0,
            'current_price': 150.0,
            'volume_ratio': 1.2,
            'available_cash': 50000.0,
            'total_pnl': 1500.0,
            'position_count': 2,
            'option_delta': 0.6,
            'option_premium': 500.0,
            'stock_margin': 1500.0,
            'confidence_level': 0.8,
            'notional_value': 30000.0,
            'risk_tolerance_encoded': 2,  # aggressive
            'investment_style_encoded': 2,  # momentum
            'option_experience_encoded': 1,  # basic
            'financial_knowledge_encoded': 1,  # intermediate
            'decision_speed_encoded': 2,  # fast
            'cash_to_notional_ratio': 50000.0 / 30000.0,
            'premium_to_margin_ratio': 500.0 / 1500.0,
            'pnl_per_position': 1500.0 / 2
        }
        
        result = model.predict(test_features)
        
        print(f"\nğŸ“Š é¢„æµ‹ç»“æœ:")
        print(f"   é€‰æ‹©: {'æœŸæƒ' if result['prediction'] == 1 else 'è‚¡ç¥¨'}")
        print(f"   ç½®ä¿¡åº¦: {result['confidence']:.2%}")
        print(f"   æœŸæƒæ¦‚ç‡: {result['probabilities']['option']:.2%}")
        print(f"   è‚¡ç¥¨æ¦‚ç‡: {result['probabilities']['stock']:.2%}")
        
    else:
        # é»˜è®¤ï¼šæ˜¾ç¤ºå¸®åŠ©
        print(f"""
ä½¿ç”¨æ–¹æ³•:
    python ml_decision_tree.py train    # è®­ç»ƒæ¨¡å‹
    python ml_decision_tree.py test     # æµ‹è¯•é¢„æµ‹
        """)

