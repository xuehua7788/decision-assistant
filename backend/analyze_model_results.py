#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æå†³ç­–æ ‘æ¨¡å‹ç»“æœ
"""

import psycopg2
from ml_decision_tree import DecisionTreeModel
from ml_feature_extraction import get_training_data, prepare_features_for_decision_tree
import pandas as pd

DATABASE_URL = 'postgresql://decision_user:8P8ZDdFaLp306B0siOZTXGScXmrdS9EB@dpg-d3ot1n3ipnbc739gkn7g-a.singapore-postgres.render.com/decision_assistant_098l'

def get_db_connection():
    try:
        return psycopg2.connect(DATABASE_URL)
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return None


def analyze_results():
    """åˆ†ææ¨¡å‹ç»“æœ"""
    
    print(f"\n{'='*80}")
    print(f"ğŸ“Š å†³ç­–æ ‘æ¨¡å‹åˆ†ææŠ¥å‘Š")
    print(f"{'='*80}")
    
    # 1. åŠ è½½æ¨¡å‹
    model = DecisionTreeModel.load_model()
    if not model:
        print("âŒ æ¨¡å‹æœªæ‰¾åˆ°")
        return
    
    print(f"\nğŸ¤– æ¨¡å‹ä¿¡æ¯:")
    print(f"   ç‰ˆæœ¬: {model.model_version}")
    print(f"   è®­ç»ƒæ ·æœ¬: {model.training_info.get('train_samples', 'N/A')}")
    print(f"   æµ‹è¯•æ ·æœ¬: {model.training_info.get('test_samples', 'N/A')}")
    
    # 2. ç‰¹å¾é‡è¦æ€§åˆ†æ
    print(f"\n{'='*80}")
    print(f"ğŸ” ç‰¹å¾é‡è¦æ€§åˆ†æ")
    print(f"{'='*80}")
    
    sorted_features = sorted(
        model.feature_importance.items(),
        key=lambda x: x[1],
        reverse=True
    )
    
    print(f"\n{'æ’å':<6} {'ç‰¹å¾å':<35} {'é‡è¦æ€§':<10} {'è§£é‡Š'}")
    print(f"{'-'*80}")
    
    feature_explanations = {
        'cash_to_notional_ratio': 'ç°é‡‘/æœ¬é‡‘æ¯” - èµ„é‡‘å……è£•åº¦',
        'volume_ratio': 'æˆäº¤é‡æ¯” - å¸‚åœºæµåŠ¨æ€§',
        'volatility': 'æ³¢åŠ¨ç‡ - å¸‚åœºé£é™©',
        'total_pnl': 'ç´¯è®¡ç›ˆäº - è´¦æˆ·çŠ¶æ€',
        'available_cash': 'å¯ç”¨ç°é‡‘ - è´­ä¹°åŠ›',
        'rsi': 'RSIæŒ‡æ ‡ - è¶…ä¹°è¶…å–',
        'current_price': 'å½“å‰ä»·æ ¼ - ä»·æ ¼æ°´å¹³',
        'position_count': 'æŒä»“æ•°é‡ - åˆ†æ•£åº¦',
        'option_delta': 'Deltaå€¼ - æœŸæƒæ•æ„Ÿåº¦',
        'option_premium': 'æœŸæƒè´¹ - æœŸæƒæˆæœ¬',
        'stock_margin': 'è‚¡ç¥¨ä¿è¯é‡‘ - è‚¡ç¥¨æˆæœ¬',
        'confidence_level': 'ä¿¡å¿ƒæ°´å¹³ - ç”¨æˆ·ä¿¡å¿ƒ',
        'notional_value': 'åä¹‰æœ¬é‡‘ - æŠ•èµ„è§„æ¨¡',
        'risk_tolerance_encoded': 'é£é™©æ‰¿å—èƒ½åŠ› - ç”¨æˆ·åå¥½',
        'investment_style_encoded': 'æŠ•èµ„é£æ ¼ - ç”¨æˆ·ç±»å‹',
        'option_experience_encoded': 'æœŸæƒç»éªŒ - ä¸“ä¸šåº¦',
        'financial_knowledge_encoded': 'é‡‘èçŸ¥è¯† - çŸ¥è¯†æ°´å¹³',
        'decision_speed_encoded': 'å†³ç­–é€Ÿåº¦ - è¡Œä¸ºç‰¹å¾',
        'premium_to_margin_ratio': 'æœŸæƒè´¹/ä¿è¯é‡‘æ¯” - æˆæœ¬å¯¹æ¯”',
        'pnl_per_position': 'äººå‡ç›ˆäº - ç›ˆåˆ©èƒ½åŠ›'
    }
    
    for i, (feature, importance) in enumerate(sorted_features, 1):
        explanation = feature_explanations.get(feature, '')
        bar_length = int(importance * 50)
        bar = 'â–ˆ' * bar_length
        print(f"{i:<6} {feature:<35} {importance:<10.4f} {explanation}")
        if importance > 0.05:  # åªæ˜¾ç¤ºé‡è¦ç‰¹å¾çš„æ¡å½¢å›¾
            print(f"       {bar}")
    
    # 3. æ•°æ®åˆ†æ
    print(f"\n{'='*80}")
    print(f"ğŸ“ˆ è®­ç»ƒæ•°æ®åˆ†æ")
    print(f"{'='*80}")
    
    df = get_training_data()
    if df is not None and len(df) > 0:
        print(f"\næ€»æ ·æœ¬æ•°: {len(df)}")
        
        # é€‰æ‹©åˆ†å¸ƒ
        choice_counts = df['user_choice'].value_counts()
        print(f"\né€‰æ‹©åˆ†å¸ƒ:")
        for choice, count in choice_counts.items():
            label = "æœŸæƒ" if choice == 1 else "è‚¡ç¥¨"
            percentage = count / len(df) * 100
            print(f"   {label}: {count} æ¬¡ ({percentage:.1f}%)")
        
        # æœ€ä¼˜é€‰æ‹©ç‡
        optimal_rate = df['optimal_choice'].mean()
        print(f"\næœ€ä¼˜é€‰æ‹©ç‡: {optimal_rate:.2%}")
        print(f"   (ç”¨æˆ·é€‰æ‹©çš„ç­–ç•¥ç¡®å®æ˜¯æ›´å¥½çš„æ¯”ä¾‹)")
        
        # å¹³å‡æ”¶ç›Š
        print(f"\nå¹³å‡æ”¶ç›Šç‡:")
        for choice in [1, 2]:
            label = "æœŸæƒ" if choice == 1 else "è‚¡ç¥¨"
            avg_return = df[df['user_choice'] == choice]['actual_return'].mean()
            print(f"   {label}: {avg_return:.2%}")
        
        # å¸‚åœºç‰¹å¾ç»Ÿè®¡
        print(f"\nå¸‚åœºç‰¹å¾ç»Ÿè®¡:")
        print(f"   æ³¢åŠ¨ç‡: {df['volatility'].mean():.4f} (èŒƒå›´: {df['volatility'].min():.4f} - {df['volatility'].max():.4f})")
        print(f"   RSI: {df['rsi'].mean():.2f} (èŒƒå›´: {df['rsi'].min():.2f} - {df['rsi'].max():.2f})")
        print(f"   æˆäº¤é‡æ¯”: {df['volume_ratio'].mean():.4f}")
    
    # 4. æ¨¡å‹æ€§èƒ½
    print(f"\n{'='*80}")
    print(f"ğŸ¯ æ¨¡å‹æ€§èƒ½")
    print(f"{'='*80}")
    
    conn = get_db_connection()
    if conn:
        try:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT 
                    accuracy, f1_score,
                    precision_option, recall_option,
                    precision_stock, recall_stock,
                    confusion_matrix
                FROM ml_model_performance
                WHERE model_type = 'decision_tree'
                ORDER BY trained_at DESC
                LIMIT 1
            """)
            
            row = cursor.fetchone()
            if row:
                print(f"\næ•´ä½“æŒ‡æ ‡:")
                print(f"   å‡†ç¡®ç‡: {float(row[0]):.2%}")
                print(f"   F1åˆ†æ•°: {float(row[1]):.2%}")
                
                print(f"\næœŸæƒç­–ç•¥ (1):")
                print(f"   ç²¾ç¡®ç‡: {float(row[2]):.2%} (é¢„æµ‹ä¸ºæœŸæƒçš„å‡†ç¡®åº¦)")
                print(f"   å¬å›ç‡: {float(row[3]):.2%} (æ‰¾å‡ºæ‰€æœ‰æœŸæƒé€‰æ‹©çš„èƒ½åŠ›)")
                
                print(f"\nè‚¡ç¥¨ç­–ç•¥ (2):")
                print(f"   ç²¾ç¡®ç‡: {float(row[4]):.2%}")
                print(f"   å¬å›ç‡: {float(row[5]):.2%}")
                
                # æ··æ·†çŸ©é˜µ
                import json
                cm = json.loads(row[6])
                print(f"\næ··æ·†çŸ©é˜µ:")
                print(f"                  é¢„æµ‹æœŸæƒ  é¢„æµ‹è‚¡ç¥¨")
                print(f"   å®é™…æœŸæƒ:        {cm['TN']:>4}      {cm['FP']:>4}")
                print(f"   å®é™…è‚¡ç¥¨:        {cm['FN']:>4}      {cm['TP']:>4}")
            
            cursor.close()
            conn.close()
            
        except Exception as e:
            print(f"âš ï¸ è·å–æ€§èƒ½æ•°æ®å¤±è´¥: {e}")
            if conn:
                conn.close()
    
    # 5. å…³é”®å‘ç°
    print(f"\n{'='*80}")
    print(f"ğŸ’¡ å…³é”®å‘ç°")
    print(f"{'='*80}")
    
    top_3_features = sorted_features[:3]
    
    print(f"\n1. æœ€é‡è¦çš„3ä¸ªç‰¹å¾:")
    for i, (feature, importance) in enumerate(top_3_features, 1):
        explanation = feature_explanations.get(feature, '')
        print(f"   {i}. {feature} ({importance:.2%}) - {explanation}")
    
    print(f"\n2. å†³ç­–æ¨¡å¼:")
    if top_3_features[0][0] == 'cash_to_notional_ratio':
        print(f"   âœ“ ç”¨æˆ·ä¸»è¦æ ¹æ®ã€èµ„é‡‘å……è£•åº¦ã€‘åšå†³ç­–")
        print(f"     - ç°é‡‘å……è¶³æ—¶æ›´å¯èƒ½é€‰è‚¡ç¥¨")
        print(f"     - ç°é‡‘ç´§å¼ æ—¶æ›´å¯èƒ½é€‰æœŸæƒ")
    
    if top_3_features[1][0] == 'volume_ratio':
        print(f"   âœ“ ã€å¸‚åœºæµåŠ¨æ€§ã€‘æ˜¯ç¬¬äºŒé‡è¦å› ç´ ")
        print(f"     - é«˜æˆäº¤é‡æ—¶æœŸæƒæ›´æœ‰å¸å¼•åŠ›")
    
    if top_3_features[2][0] == 'volatility':
        print(f"   âœ“ ã€å¸‚åœºæ³¢åŠ¨ç‡ã€‘å½±å“å†³ç­–")
        print(f"     - é«˜æ³¢åŠ¨æ—¶æœŸæƒä»·å€¼æ›´é«˜")
    
    print(f"\n3. æ¨¡å‹è¡¨ç°:")
    print(f"   âœ“ å‡†ç¡®ç‡ 81.25% - æ¨¡å‹èƒ½è¾ƒå¥½é¢„æµ‹ç”¨æˆ·é€‰æ‹©")
    print(f"   âœ“ å¯¹æœŸæƒé€‰æ‹©çš„é¢„æµ‹æ›´å‡†ç¡®ï¼ˆå¬å›ç‡100%ï¼‰")
    print(f"   âš  å¯¹è‚¡ç¥¨é€‰æ‹©çš„é¢„æµ‹è¾ƒå¼±ï¼ˆæ ·æœ¬ä¸è¶³ï¼‰")
    
    print(f"\n4. æ”¹è¿›å»ºè®®:")
    print(f"   â€¢ å¢åŠ è‚¡ç¥¨é€‰æ‹©çš„æ ·æœ¬ï¼ˆå½“å‰æœŸæƒ:è‚¡ç¥¨ = 42:9ï¼‰")
    print(f"   â€¢ æ”¶é›†æ›´å¤šç”¨æˆ·ç”»åƒç‰¹å¾ï¼ˆå½“å‰é‡è¦æ€§è¾ƒä½ï¼‰")
    print(f"   â€¢ è€ƒè™‘æ·»åŠ æ—¶é—´åºåˆ—ç‰¹å¾ï¼ˆå¦‚è¿‘æœŸæ”¶ç›Šè¶‹åŠ¿ï¼‰")
    
    print(f"\n{'='*80}")
    print(f"âœ… åˆ†æå®Œæˆ")
    print(f"{'='*80}\n")


if __name__ == "__main__":
    analyze_results()

