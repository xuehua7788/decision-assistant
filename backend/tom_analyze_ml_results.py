#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®©Tomåˆ†æå†³ç­–æ ‘æ¨¡å‹ç»“æœ
"""

import os
import openai
from ml_decision_tree import DecisionTreeModel
from ml_feature_extraction import get_training_data
import json

# è®¾ç½®OpenAI API
openai.api_key = os.getenv('OPENAI_API_KEY')

def get_model_summary():
    """è·å–æ¨¡å‹æ‘˜è¦æ•°æ®"""
    model = DecisionTreeModel.load_model()
    if not model:
        return None
    
    df = get_training_data()
    if df is None or len(df) == 0:
        return None
    
    # ç‰¹å¾é‡è¦æ€§
    top_features = sorted(
        model.feature_importance.items(),
        key=lambda x: x[1],
        reverse=True
    )[:5]
    
    # é€‰æ‹©åˆ†å¸ƒ
    choice_counts = df['user_choice'].value_counts()
    option_count = choice_counts.get(1, 0)
    stock_count = choice_counts.get(2, 0)
    
    # å¹³å‡æ”¶ç›Š
    option_return = df[df['user_choice'] == 1]['actual_return'].mean()
    stock_return = df[df['user_choice'] == 2]['actual_return'].mean()
    
    # æœ€ä¼˜é€‰æ‹©ç‡
    optimal_rate = df['optimal_choice'].mean()
    
    summary = {
        'model_version': model.model_version,
        'train_samples': model.training_info.get('train_samples', 0),
        'test_samples': model.training_info.get('test_samples', 0),
        'total_samples': len(df),
        'accuracy': 0.8125,  # ä»è®­ç»ƒç»“æœ
        'f1_score': 0.7284,
        'top_features': [
            {'name': name, 'importance': float(importance), 'rank': i+1}
            for i, (name, importance) in enumerate(top_features)
        ],
        'choice_distribution': {
            'option': int(option_count),
            'stock': int(stock_count),
            'option_percentage': float(option_count / len(df) * 100),
            'stock_percentage': float(stock_count / len(df) * 100)
        },
        'average_returns': {
            'option': float(option_return),
            'stock': float(stock_return)
        },
        'optimal_choice_rate': float(optimal_rate),
        'market_stats': {
            'avg_volatility': float(df['volatility'].mean()),
            'avg_rsi': float(df['rsi'].mean()),
            'volatility_range': [float(df['volatility'].min()), float(df['volatility'].max())]
        }
    }
    
    return summary


def ask_tom_to_analyze(summary):
    """è®©Tomåˆ†ææ¨¡å‹ç»“æœ"""
    
    prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡åŒ–åˆ†æå¸ˆTomã€‚è¯·åˆ†æä»¥ä¸‹å†³ç­–æ ‘æ¨¡å‹çš„è®­ç»ƒç»“æœï¼Œå¹¶ç»™å‡ºç®€çŸ­çš„åˆ†æå’Œå»ºè®®ã€‚

## æ¨¡å‹è®­ç»ƒç»“æœ

**åŸºæœ¬ä¿¡æ¯ï¼š**
- æ€»æ ·æœ¬æ•°ï¼š{summary['total_samples']} ä¸ªå·²å¹³ä»“äº¤æ˜“
- è®­ç»ƒé›†ï¼š{summary['train_samples']} æ ·æœ¬
- æµ‹è¯•é›†ï¼š{summary['test_samples']} æ ·æœ¬
- æ¨¡å‹å‡†ç¡®ç‡ï¼š{summary['accuracy']:.2%}
- F1åˆ†æ•°ï¼š{summary['f1_score']:.2%}

**ç”¨æˆ·å†³ç­–åˆ†å¸ƒï¼š**
- é€‰æ‹©æœŸæƒï¼š{summary['choice_distribution']['option']} æ¬¡ ({summary['choice_distribution']['option_percentage']:.1f}%)
- é€‰æ‹©è‚¡ç¥¨ï¼š{summary['choice_distribution']['stock']} æ¬¡ ({summary['choice_distribution']['stock_percentage']:.1f}%)

**å¹³å‡æ”¶ç›Šç‡ï¼š**
- æœŸæƒç­–ç•¥ï¼š{summary['average_returns']['option']:.2%}
- è‚¡ç¥¨ç­–ç•¥ï¼š{summary['average_returns']['stock']:.2%}

**æœ€ä¼˜é€‰æ‹©ç‡ï¼š**
- {summary['optimal_choice_rate']:.2%} (ç”¨æˆ·é€‰æ‹©ç¡®å®æ˜¯æ›´å¥½ç­–ç•¥çš„æ¯”ä¾‹)

**Top 5 ç‰¹å¾é‡è¦æ€§ï¼š**
{chr(10).join([f"{i}. {f['name']}: {f['importance']:.2%}" for i, f in enumerate(summary['top_features'], 1)])}

**å¸‚åœºç¯å¢ƒï¼š**
- å¹³å‡æ³¢åŠ¨ç‡ï¼š{summary['market_stats']['avg_volatility']:.4f}
- å¹³å‡RSIï¼š{summary['market_stats']['avg_rsi']:.2f}
- æ³¢åŠ¨ç‡èŒƒå›´ï¼š{summary['market_stats']['volatility_range'][0]:.4f} - {summary['market_stats']['volatility_range'][1]:.4f}

---

è¯·ä»ä»¥ä¸‹è§’åº¦ç»™å‡ºåˆ†æï¼š
1. **æ¨¡å‹è¡¨ç°è¯„ä»·**ï¼ˆå‡†ç¡®ç‡æ˜¯å¦å¯æ¥å—ï¼Ÿï¼‰
2. **ç”¨æˆ·è¡Œä¸ºæ´å¯Ÿ**ï¼ˆç”¨æˆ·ä¸ºä»€ä¹ˆæ›´å€¾å‘æœŸæƒï¼Ÿï¼‰
3. **ç‰¹å¾é‡è¦æ€§è§£è¯»**ï¼ˆä¸ºä»€ä¹ˆè¿™äº›ç‰¹å¾æœ€é‡è¦ï¼Ÿï¼‰
4. **é£é™©æç¤º**ï¼ˆæ¨¡å‹æœ‰ä»€ä¹ˆå±€é™æ€§ï¼Ÿï¼‰
5. **æ”¹è¿›å»ºè®®**ï¼ˆå¦‚ä½•æå‡æ¨¡å‹æ•ˆæœï¼Ÿï¼‰

è¦æ±‚ï¼š
- è¯­è¨€ç®€æ´ä¸“ä¸šï¼Œæ¯ä¸ªè§’åº¦2-3å¥è¯
- çªå‡ºå…³é”®å‘ç°
- ç»™å‡ºå¯æ“ä½œçš„å»ºè®®
- æ€»å­—æ•°æ§åˆ¶åœ¨400å­—ä»¥å†…
"""

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯Tomï¼Œä¸€ä½ä¸“ä¸šçš„é‡åŒ–åˆ†æå¸ˆå’ŒAIç®—æ³•ä¸“å®¶ã€‚ä½ æ“…é•¿è§£è¯»æœºå™¨å­¦ä¹ æ¨¡å‹ç»“æœï¼Œå¹¶ç»™å‡ºå®ç”¨çš„æŠ•èµ„å»ºè®®ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.7,
            max_tokens=800
        )
        
        analysis = response.choices[0].message.content
        return analysis
        
    except Exception as e:
        print(f"âŒ Tomåˆ†æå¤±è´¥: {e}")
        return None


def main():
    print(f"\n{'='*80}")
    print(f"ğŸ¤– Tomçš„å†³ç­–æ ‘æ¨¡å‹åˆ†æ")
    print(f"{'='*80}\n")
    
    # 1. è·å–æ¨¡å‹æ‘˜è¦
    print(f"ğŸ“Š æ­£åœ¨æ”¶é›†æ¨¡å‹æ•°æ®...")
    summary = get_model_summary()
    
    if not summary:
        print(f"âŒ æ— æ³•è·å–æ¨¡å‹æ•°æ®")
        return
    
    print(f"âœ… æ•°æ®æ”¶é›†å®Œæˆ")
    print(f"   - æ€»æ ·æœ¬: {summary['total_samples']}")
    print(f"   - å‡†ç¡®ç‡: {summary['accuracy']:.2%}")
    print(f"   - Topç‰¹å¾: {summary['top_features'][0]['name']}")
    
    # 2. è®©Tomåˆ†æ
    print(f"\nğŸ” Tomæ­£åœ¨åˆ†æ...")
    analysis = ask_tom_to_analyze(summary)
    
    if not analysis:
        print(f"âŒ Tomåˆ†æå¤±è´¥")
        return
    
    # 3. æ˜¾ç¤ºåˆ†æç»“æœ
    print(f"\n{'='*80}")
    print(f"ğŸ’¡ Tomçš„åˆ†ææŠ¥å‘Š")
    print(f"{'='*80}\n")
    print(analysis)
    print(f"\n{'='*80}\n")
    
    # 4. ä¿å­˜åˆ°æ–‡ä»¶
    output = {
        'timestamp': summary['model_version'],
        'summary': summary,
        'tom_analysis': analysis
    }
    
    with open('tom_ml_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… åˆ†æç»“æœå·²ä¿å­˜åˆ°: tom_ml_analysis.json\n")


if __name__ == "__main__":
    main()

